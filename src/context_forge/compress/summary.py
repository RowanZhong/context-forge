"""
LLM æ‘˜è¦å‹ç¼©å™¨ â€” ä½¿ç”¨ LLM ç”ŸæˆæŠ½è±¡æ‘˜è¦ã€‚

â†’ 6.3.3 Write ç­–ç•¥ï¼šRolling Summary ä¸ Context Distillation

æŠ½è±¡æ‘˜è¦æ˜¯æœ€é«˜è´¨é‡çš„å‹ç¼©æ–¹å¼ï¼Œå¯ä»¥å°†é•¿å¯¹è¯å‹ç¼©ä¸ºç²¾ç‚¼çš„è¦ç‚¹ã€‚
ä½†å®ƒä¾èµ– LLM è°ƒç”¨ï¼Œæœ‰æˆæœ¬å’Œå»¶è¿Ÿã€‚å› æ­¤æœ¬å‹ç¼©å™¨æä¾› fallback æœºåˆ¶ï¼š
LLM è°ƒç”¨å¤±è´¥æ—¶è‡ªåŠ¨é™çº§åˆ°æˆªæ–­å‹ç¼©ã€‚

# [Design Decision] å¼‚æ­¥ä¼˜å…ˆè®¾è®¡ï¼Œæ”¯æŒ LLM API è°ƒç”¨ã€‚
# ä½¿ç”¨ LLMProvider Protocol è§£è€¦å…·ä½“çš„ LLM å®¢æˆ·ç«¯ï¼ˆOpenAI/Anthropic/æœ¬åœ°ï¼‰ã€‚
"""

from __future__ import annotations

import logging
from typing import Protocol

from context_forge.compress.base import CompressContext, CompressionResult
from context_forge.compress.truncation import TruncationCompressor, TruncationStrategy
from context_forge.errors.exceptions import CompressionError
from context_forge.models.provenance import Provenance, SourceType
from context_forge.models.segment import Segment, SegmentType

logger = logging.getLogger(__name__)


class LLMProvider(Protocol):
    """
    LLM æä¾›è€…åè®® â€” è§£è€¦å…·ä½“çš„ LLM å®¢æˆ·ç«¯ã€‚

    # [Design Decision] ä½¿ç”¨ Protocol è€Œéå…·ä½“ç±»ï¼Œ
    # å…è®¸ç”¨æˆ·æ³¨å…¥ä»»ä½•ç¬¦åˆæ¥å£çš„ LLM å®¢æˆ·ç«¯ï¼ˆOpenAI/Anthropic/æœ¬åœ°æ¨¡å‹ï¼‰ã€‚
    """

    async def generate(self, prompt: str, max_tokens: int = 500) -> str:
        """
        ç”Ÿæˆæ–‡æœ¬ã€‚

        å‚æ•°:
            prompt: è¾“å…¥æç¤º
            max_tokens: æœ€å¤§ç”Ÿæˆ Token æ•°

        è¿”å›:
            ç”Ÿæˆçš„æ–‡æœ¬

        æŠ›å‡º:
            ä»»ä½• LLM è°ƒç”¨å¼‚å¸¸
        """
        ...


class LLMSummaryCompressor:
    """
    LLM æ‘˜è¦å‹ç¼©å™¨ â€” ä½¿ç”¨ LLM ç”ŸæˆæŠ½è±¡æ‘˜è¦ã€‚

    â†’ 6.3.3 Rolling Summary å®ç°

    æ‘˜è¦å‹ç¼©å™¨å°†å¤šæ¡ Segment åˆå¹¶ä¸ºä¸€æ¡ SUMMARY ç±»å‹çš„ Segmentã€‚
    æ‘˜è¦ä¿ç•™å…³é”®ä¿¡æ¯ï¼Œå¤§å¹…å‡å°‘ Token æ¶ˆè€—ï¼ˆé€šå¸¸å‹ç¼©æ¯” 0.1-0.3ï¼‰ã€‚

    åŸºæœ¬ç”¨æ³•::

        from my_llm import MyLLMClient

        provider = MyLLMClient(api_key="...")
        compressor = LLMSummaryCompressor(provider)
        result = await compressor.compress(segments, context)

    å¯ç”¨ fallbackï¼ˆæ¨èï¼‰::

        compressor = LLMSummaryCompressor(
            provider,
            enable_fallback=True,  # LLM å¤±è´¥æ—¶é™çº§åˆ°æˆªæ–­
        )

    å±æ€§:
        provider: LLM æä¾›è€…ï¼ˆå®ç° LLMProvider Protocolï¼‰
        enable_fallback: æ˜¯å¦å¯ç”¨ fallbackï¼ˆé»˜è®¤ Trueï¼‰
        max_summary_tokens: æ‘˜è¦æœ€å¤§ Token æ•°ï¼ˆé»˜è®¤ 500ï¼‰
    """

    def __init__(
        self,
        provider: LLMProvider | None = None,
        enable_fallback: bool = True,
        max_summary_tokens: int = 500,
    ):
        """
        åˆå§‹åŒ– LLM æ‘˜è¦å‹ç¼©å™¨ã€‚

        å‚æ•°:
            provider: LLM æä¾›è€…ï¼ŒNone æ—¶å¼ºåˆ¶ä½¿ç”¨ fallback
            enable_fallback: æ˜¯å¦å¯ç”¨ fallbackï¼ˆé»˜è®¤ Trueï¼‰
            max_summary_tokens: æ‘˜è¦æœ€å¤§ Token æ•°ï¼ˆé»˜è®¤ 500ï¼‰
        """
        self._provider = provider
        self._enable_fallback = enable_fallback
        self._max_summary_tokens = max_summary_tokens
        self._fallback_compressor = TruncationCompressor(
            strategy=TruncationStrategy.TAIL
        )

    @property
    def name(self) -> str:
        """å‹ç¼©å™¨åç§°ã€‚"""
        return "llm_summary"

    async def compress(
        self, segments: list[Segment], context: CompressContext
    ) -> CompressionResult:
        """
        ä½¿ç”¨ LLM ç”ŸæˆæŠ½è±¡æ‘˜è¦ã€‚

        â†’ 6.3.3 Rolling Summary ç®—æ³•

        æµç¨‹:
        1. åˆå¹¶æ‰€æœ‰ Segment çš„å†…å®¹
        2. æ„é€ æ‘˜è¦æç¤ºï¼ˆPromptï¼‰
        3. è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦
        4. åˆ›å»º SUMMARY ç±»å‹çš„ Segment
        5. å¤±è´¥æ—¶é™çº§åˆ° fallbackï¼ˆå¦‚æœå¯ç”¨ï¼‰

        å‚æ•°:
            segments: å¾…æ‘˜è¦çš„ Segment åˆ—è¡¨
            context: å‹ç¼©ä¸Šä¸‹æ–‡

        è¿”å›:
            CompressionResultï¼ŒåŒ…å«å•æ¡æ‘˜è¦ Segment

        æŠ›å‡º:
            CompressionError: LLM è°ƒç”¨å¤±è´¥ä¸”æœªå¯ç”¨ fallback
        """
        if not segments:
            return CompressionResult(
                compressed_segments=[],
                original_token_count=0,
                compressed_token_count=0,
                method=self.name,
                parent_segment_ids=[],
            )

        # è®¡ç®—åŸå§‹æ€» Token æ•°
        original_tokens = sum(seg.token_count or 0 for seg in segments)
        parent_ids = [seg.id for seg in segments]

        # å¦‚æœæ²¡æœ‰ providerï¼Œç›´æ¥ä½¿ç”¨ fallback
        if self._provider is None:
            if self._enable_fallback:
                logger.warning(
                    "LLM æä¾›è€…æœªé…ç½®ï¼Œé™çº§åˆ°æˆªæ–­å‹ç¼©ã€‚"
                    "æç¤ºï¼šä¼ å…¥ LLMProvider å®ä¾‹ä»¥å¯ç”¨æ‘˜è¦å‹ç¼©ã€‚"
                )
                return await self._fallback_compress(segments, context)
            else:
                raise CompressionError(
                    what="LLM æ‘˜è¦å‹ç¼©å¤±è´¥",
                    why="æœªé…ç½® LLM æä¾›è€…ä¸”æœªå¯ç”¨ fallback",
                    how="è¯·ä¼ å…¥ LLMProvider å®ä¾‹æˆ–è®¾ç½® enable_fallback=True",
                )

        # å°è¯•ä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦
        try:
            summary_text = await self._generate_summary(segments, context)
        except Exception as e:
            # LLM è°ƒç”¨å¤±è´¥
            if self._enable_fallback:
                logger.warning(
                    f"LLM æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼š{e}ï¼Œé™çº§åˆ°æˆªæ–­å‹ç¼©ã€‚"
                )
                return await self._fallback_compress(segments, context)
            else:
                raise CompressionError(
                    what="LLM æ‘˜è¦ç”Ÿæˆå¤±è´¥",
                    why=str(e),
                    how="æ£€æŸ¥ LLM API é…ç½®æˆ–å¯ç”¨ fallback",
                ) from e

        # åˆ›å»ºæ‘˜è¦ Segment
        summary_segment = Segment(
            type=SegmentType.SUMMARY,
            content=summary_text,
            role="assistant",  # æ‘˜è¦é€šå¸¸ä½œä¸ºåŠ©æ‰‹å›å¤
            provenance=Provenance(
                source_id=f"summary_{parent_ids[0] if parent_ids else 'empty'}",
                source_type=SourceType.COMPRESSION,
                parent_segment_ids=parent_ids,
                compression_method=self.name,
            ),
            token_count=None,  # ç”±åç»­æµæ°´çº¿é‡æ–°è®¡æ•°
        )

        # ç²—ç•¥ä¼°ç®—æ‘˜è¦ Token æ•°ï¼ˆå®é™…åº”ç”± Tokenizer è®¡æ•°ï¼‰
        # ğŸ­ ç”Ÿäº§æç¤ºï¼šè°ƒç”¨ Tokenizer è·å–ç²¾ç¡® Token æ•°
        estimated_tokens = len(summary_text) // 4

        return CompressionResult(
            compressed_segments=[summary_segment],
            original_token_count=original_tokens,
            compressed_token_count=estimated_tokens,
            method=self.name,
            parent_segment_ids=parent_ids,
        )

    async def _generate_summary(
        self, segments: list[Segment], context: CompressContext
    ) -> str:
        """
        è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦ã€‚

        â†’ 6.3.3.1 æ‘˜è¦ Prompt è®¾è®¡

        Prompt è®¾è®¡åŸåˆ™:
        - æ˜ç¡®ä»»åŠ¡ï¼šæ€»ç»“å¯¹è¯è¦ç‚¹
        - æŒ‡å®šæ ¼å¼ï¼šç®€æ´çš„è¦ç‚¹åˆ—è¡¨
        - æ§åˆ¶é•¿åº¦ï¼šé™åˆ¶è¾“å‡º Token æ•°

        å‚æ•°:
            segments: å¾…æ‘˜è¦çš„ Segment åˆ—è¡¨
            context: å‹ç¼©ä¸Šä¸‹æ–‡

        è¿”å›:
            æ‘˜è¦æ–‡æœ¬
        """
        # åˆå¹¶æ‰€æœ‰ Segment çš„å†…å®¹
        combined_content = "\n\n".join(
            f"[{seg.type.value.upper()}] {seg.content}" for seg in segments
        )

        # æ„é€ æ‘˜è¦æç¤º
        prompt = f"""è¯·æ€»ç»“ä»¥ä¸‹å†…å®¹çš„å…³é”®è¦ç‚¹ï¼Œä¿ç•™æ ¸å¿ƒä¿¡æ¯ã€‚
è¾“å‡ºæ ¼å¼ï¼šç®€æ´çš„è¦ç‚¹åˆ—è¡¨ï¼ˆ2-5 æ¡ï¼‰ã€‚

å†…å®¹ï¼š
{combined_content}

æ€»ç»“ï¼š"""

        # è°ƒç”¨ LLM ç”Ÿæˆ
        if self._provider is None:
            raise ValueError("LLM æä¾›è€…æœªé…ç½®")

        summary = await self._provider.generate(
            prompt, max_tokens=self._max_summary_tokens
        )

        return summary.strip()

    async def _fallback_compress(
        self, segments: list[Segment], context: CompressContext
    ) -> CompressionResult:
        """
        é™çº§åˆ°æˆªæ–­å‹ç¼©ã€‚

        å‚æ•°:
            segments: å¾…å‹ç¼©çš„ Segment åˆ—è¡¨
            context: å‹ç¼©ä¸Šä¸‹æ–‡

        è¿”å›:
            æˆªæ–­å‹ç¼©ç»“æœ
        """
        return await self._fallback_compressor.compress(segments, context)
