"""
LLM æ‘˜è¦å‹ç¼©å™¨ â€” ä½¿ç”¨ LLM ç”ŸæˆæŠ½è±¡æ‘˜è¦ï¼ˆå«æ»šåŠ¨æ‘˜è¦ï¼‰ã€‚

â†’ 6.3.3 Write ç­–ç•¥ï¼šRolling Summary ä¸ Context Distillation

æä¾›ä¸¤ç§æ‘˜è¦å‹ç¼©å™¨ï¼š
- LLMSummaryCompressorï¼šæ— çŠ¶æ€ä¸€æ¬¡æ€§æ‘˜è¦
- RollingSummaryCompressorï¼šæœ‰çŠ¶æ€å¢é‡æ»šåŠ¨æ‘˜è¦ï¼ˆè·¨ build() è°ƒç”¨ä¿ç•™å†å²ï¼‰

# [Design Decision] å¼‚æ­¥ä¼˜å…ˆè®¾è®¡ï¼Œæ”¯æŒ LLM API è°ƒç”¨ã€‚
# ä½¿ç”¨ LLMProvider Protocol è§£è€¦å…·ä½“çš„ LLM å®¢æˆ·ç«¯ï¼ˆOpenAI/Anthropic/æœ¬åœ°ï¼‰ã€‚
"""

from __future__ import annotations

import logging
from typing import Protocol

from context_forge.compress.base import CompressContext, CompressionResult
from context_forge.compress.truncation import TruncationCompressor, TruncationStrategy
from context_forge.errors.exceptions import CompressionError
from context_forge.models.provenance import Provenance, SourceType
from context_forge.models.segment import Segment, SegmentType

logger = logging.getLogger(__name__)


class LLMProvider(Protocol):
    """LLM æä¾›è€…åè®® â€” è§£è€¦å…·ä½“çš„ LLM å®¢æˆ·ç«¯ã€‚"""

    async def generate(self, prompt: str, max_tokens: int = 500) -> str:
        """ç”Ÿæˆæ–‡æœ¬ã€‚"""
        ...


class LLMSummaryCompressor:
    """
    LLM æ‘˜è¦å‹ç¼©å™¨ â€” ä½¿ç”¨ LLM ç”ŸæˆæŠ½è±¡æ‘˜è¦ï¼ˆæ— çŠ¶æ€ï¼‰ã€‚

    â†’ 6.3.3 Rolling Summary å®ç°

    å±æ€§:
        provider: LLM æä¾›è€…ï¼ˆå®ç° LLMProvider Protocolï¼‰
        enable_fallback: æ˜¯å¦å¯ç”¨ fallbackï¼ˆé»˜è®¤ Trueï¼‰
        max_summary_tokens: æ‘˜è¦æœ€å¤§ Token æ•°ï¼ˆé»˜è®¤ 500ï¼‰
    """

    def __init__(
        self,
        provider: LLMProvider | None = None,
        enable_fallback: bool = True,
        max_summary_tokens: int = 500,
    ):
        """åˆå§‹åŒ– LLM æ‘˜è¦å‹ç¼©å™¨ã€‚"""
        self._provider = provider
        self._enable_fallback = enable_fallback
        self._max_summary_tokens = max_summary_tokens
        self._fallback_compressor = TruncationCompressor(
            strategy=TruncationStrategy.TAIL
        )

    @property
    def name(self) -> str:
        """å‹ç¼©å™¨åç§°ã€‚"""
        return "llm_summary"

    async def compress(
        self, segments: list[Segment], context: CompressContext
    ) -> CompressionResult:
        """ä½¿ç”¨ LLM ç”ŸæˆæŠ½è±¡æ‘˜è¦ã€‚"""
        if not segments:
            return CompressionResult(
                compressed_segments=[], original_token_count=0,
                compressed_token_count=0, method=self.name, parent_segment_ids=[],
            )

        original_tokens = sum(seg.token_count or 0 for seg in segments)
        parent_ids = [seg.id for seg in segments]

        if self._provider is None:
            if self._enable_fallback:
                logger.warning(
                    "LLM æä¾›è€…æœªé…ç½®ï¼Œé™çº§åˆ°æˆªæ–­å‹ç¼©ã€‚"
                    "æç¤ºï¼šä¼ å…¥ LLMProvider å®ä¾‹ä»¥å¯ç”¨æ‘˜è¦å‹ç¼©ã€‚"
                )
                return await self._fallback_compress(segments, context)
            else:
                raise CompressionError(
                    what="LLM æ‘˜è¦å‹ç¼©å¤±è´¥",
                    why="æœªé…ç½® LLM æä¾›è€…ä¸”æœªå¯ç”¨ fallback",
                    how="è¯·ä¼ å…¥ LLMProvider å®ä¾‹æˆ–è®¾ç½® enable_fallback=True",
                )

        try:
            summary_text = await self._generate_summary(segments, context)
        except Exception as e:
            if self._enable_fallback:
                logger.warning(
                    f"LLM æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼š{e}ï¼Œé™çº§åˆ°æˆªæ–­å‹ç¼©ã€‚"
                )
                return await self._fallback_compress(segments, context)
            else:
                raise CompressionError(
                    what="LLM æ‘˜è¦ç”Ÿæˆå¤±è´¥", why=str(e),
                    how="æ£€æŸ¥ LLM API é…ç½®æˆ–å¯ç”¨ fallback",
                ) from e

        summary_segment = Segment(
            type=SegmentType.SUMMARY, content=summary_text, role="assistant",
            provenance=Provenance(
                source_id=f"summary_{parent_ids[0] if parent_ids else 'empty'}",
                source_type=SourceType.COMPRESSION,
                parent_segment_ids=parent_ids, compression_method=self.name,
            ),
            token_count=None,
        )

        # ğŸ­ ç”Ÿäº§æç¤ºï¼šè°ƒç”¨ Tokenizer è·å–ç²¾ç¡® Token æ•°
        estimated_tokens = len(summary_text) // 4

        return CompressionResult(
            compressed_segments=[summary_segment],
            original_token_count=original_tokens,
            compressed_token_count=estimated_tokens,
            method=self.name, parent_segment_ids=parent_ids,
        )

    async def _generate_summary(
        self, segments: list[Segment], context: CompressContext
    ) -> str:
        """è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦ã€‚"""
        combined_content = "\n\n".join(
            f"[{seg.type.value.upper()}] {seg.content}" for seg in segments
        )
        prompt = f"""è¯·æ€»ç»“ä»¥ä¸‹å†…å®¹çš„å…³é”®è¦ç‚¹ï¼Œä¿ç•™æ ¸å¿ƒä¿¡æ¯ã€‚
è¾“å‡ºæ ¼å¼ï¼šç®€æ´çš„è¦ç‚¹åˆ—è¡¨ï¼ˆ2-5 æ¡ï¼‰ã€‚

å†…å®¹ï¼š
{combined_content}

æ€»ç»“ï¼š"""

        if self._provider is None:
            raise ValueError("LLM æä¾›è€…æœªé…ç½®")

        summary = await self._provider.generate(
            prompt, max_tokens=self._max_summary_tokens
        )
        return summary.strip()

    async def _fallback_compress(
        self, segments: list[Segment], context: CompressContext
    ) -> CompressionResult:
        """é™çº§åˆ°æˆªæ–­å‹ç¼©ã€‚"""
        return await self._fallback_compressor.compress(segments, context)


class RollingSummaryCompressor:
    """
    æ»šåŠ¨æ‘˜è¦å‹ç¼©å™¨ â€” è·¨ build() è°ƒç”¨ä¿ç•™å¢é‡æ‘˜è¦çŠ¶æ€ã€‚

    â†’ 6.3.3 Rolling Summary çœŸå®å®ç°

    ä¸ LLMSummaryCompressor çš„å…³é”®åŒºåˆ«ï¼š
    - **æœ‰çŠ¶æ€**ï¼š``_previous_summary`` åœ¨å¤šæ¬¡ ``compress()`` è°ƒç”¨é—´ä¿ç•™å†å²æ‘˜è¦
    - **å¢é‡æ›´æ–°**ï¼š"ä¸Šè½®æ‘˜è¦ + æ–°æ¶ˆæ¯ â†’ æ›´æ–°æ‘˜è¦"
    - **è½®æ¬¡æ„ŸçŸ¥**ï¼šæœ€è¿‘ N è½®ä¿æŒåŸæ–‡ï¼Œä»…å¯¹æ›´æ—©è½®æ¬¡æ‰§è¡Œæ‘˜è¦

    åŸºæœ¬ç”¨æ³•::

        compressor = RollingSummaryCompressor(provider=my_llm, keep_recent_turns=3)
        result1 = await compressor.compress(segments_round1, context)  # åˆå§‹æ‘˜è¦
        result2 = await compressor.compress(segments_round2, context)  # å¢é‡æ›´æ–°
        compressor.reset()  # é‡ç½®çŠ¶æ€
    """

    def __init__(
        self,
        provider: LLMProvider | None = None,
        keep_recent_turns: int = 2,
        enable_fallback: bool = True,
        max_summary_tokens: int = 500,
    ):
        """
        åˆå§‹åŒ–æ»šåŠ¨æ‘˜è¦å‹ç¼©å™¨ã€‚

        å‚æ•°:
            provider: LLM æä¾›è€…ï¼ŒNone æ—¶å¼ºåˆ¶ä½¿ç”¨ fallback
            keep_recent_turns: ä¿ç•™æœ€è¿‘ N è½®åŸæ–‡ï¼ˆé»˜è®¤ 2ï¼‰
            enable_fallback: æ˜¯å¦å¯ç”¨ fallbackï¼ˆé»˜è®¤ Trueï¼‰
            max_summary_tokens: æ‘˜è¦æœ€å¤§ Token æ•°ï¼ˆé»˜è®¤ 500ï¼‰
        """
        self._provider = provider
        self._keep_recent_turns = max(0, keep_recent_turns)
        self._enable_fallback = enable_fallback
        self._max_summary_tokens = max_summary_tokens
        self._previous_summary: str | None = None
        self._fallback_compressor = TruncationCompressor(
            strategy=TruncationStrategy.TAIL
        )

    @property
    def name(self) -> str:
        """å‹ç¼©å™¨åç§°ã€‚"""
        return "rolling_summary"

    @property
    def has_state(self) -> bool:
        """æ˜¯å¦å­˜åœ¨ç´¯ç§¯çš„æ»šåŠ¨æ‘˜è¦çŠ¶æ€ã€‚"""
        return self._previous_summary is not None

    @property
    def previous_summary(self) -> str | None:
        """è·å–ä¸Šä¸€æ¬¡çš„æ»šåŠ¨æ‘˜è¦ï¼ˆåªè¯»ï¼‰ã€‚"""
        return self._previous_summary

    def reset(self) -> None:
        """æ¸…é™¤æ»šåŠ¨æ‘˜è¦çŠ¶æ€ï¼Œæ¢å¤åˆ°åˆå§‹çŠ¶æ€ã€‚"""
        self._previous_summary = None

    def _get_turn_number(self, seg: Segment) -> int | None:
        """å®‰å…¨è·å– Segment çš„è½®æ¬¡å·ã€‚"""
        if seg.metadata and hasattr(seg.metadata, "turn_number"):
            return seg.metadata.turn_number
        return None

    def _split_by_turns(
        self, segments: list[Segment]
    ) -> tuple[list[Segment], list[Segment]]:
        """
        æŒ‰è½®æ¬¡å°† Segment åˆ†ä¸º"å¯æ‘˜è¦"å’Œ"ä¿ç•™åŸæ–‡"ä¸¤ç»„ã€‚

        ä½¿ç”¨ metadata.turn_number åˆ¤æ–­è½®æ¬¡ã€‚è‹¥æ—  turn_numberï¼Œ
        åˆ™æŒ‰åˆ—è¡¨ä½ç½®æ¨æ–­ï¼šæœ«å°¾çš„ keep_recent_turns*2 æ¡è§†ä¸ºæœ€è¿‘è½®æ¬¡ã€‚
        """
        if self._keep_recent_turns <= 0:
            return segments, []

        # å°è¯•æŒ‰ turn_number åˆ†ç»„
        has_turn_info = any(self._get_turn_number(seg) is not None for seg in segments)

        if has_turn_info:
            turn_numbers = sorted({
                self._get_turn_number(seg)
                for seg in segments
                if self._get_turn_number(seg) is not None
            })
            if len(turn_numbers) <= self._keep_recent_turns:
                return [], segments

            cutoff_turns = set(turn_numbers[-self._keep_recent_turns:])
            older = [seg for seg in segments if self._get_turn_number(seg) not in cutoff_turns]
            recent = [seg for seg in segments if self._get_turn_number(seg) in cutoff_turns]
            return older, recent

        # æ—  turn_number æ—¶æŒ‰ä½ç½®æ¨æ–­ï¼ˆæ¯è½® user + assistant = 2 æ¡ï¼‰
        recent_count = self._keep_recent_turns * 2
        if len(segments) <= recent_count:
            return [], segments
        return segments[:-recent_count], segments[-recent_count:]

    async def compress(
        self, segments: list[Segment], context: CompressContext
    ) -> CompressionResult:
        """
        æ‰§è¡Œæ»šåŠ¨æ‘˜è¦å‹ç¼©ã€‚

        â†’ 6.3.3 Rolling Summary å¢é‡ç®—æ³•

        æµç¨‹ï¼šæŒ‰è½®æ¬¡æ‹†åˆ† â†’ æ—§è½®æ¬¡ç”Ÿæˆ/æ›´æ–°æ‘˜è¦ â†’ æœ€è¿‘è½®æ¬¡ä¿æŒåŸæ–‡ â†’ æ›´æ–°çŠ¶æ€
        """
        if not segments:
            return CompressionResult(
                compressed_segments=[], original_token_count=0,
                compressed_token_count=0, method=self.name, parent_segment_ids=[],
            )

        original_tokens = sum(seg.token_count or 0 for seg in segments)
        parent_ids = [seg.id for seg in segments]
        older_segments, recent_segments = self._split_by_turns(segments)

        # æ‰€æœ‰è½®æ¬¡éƒ½åœ¨ä¿ç•™èŒƒå›´å†…ï¼Œæ— éœ€æ‘˜è¦
        if not older_segments:
            return CompressionResult(
                compressed_segments=segments,
                original_token_count=original_tokens,
                compressed_token_count=original_tokens,
                method=self.name, parent_segment_ids=parent_ids,
                metadata={"rolling_state": "no_older_turns"},
            )

        # æ²¡æœ‰ provider â†’ fallback æˆ–æŠ¥é”™
        if self._provider is None:
            if self._enable_fallback:
                logger.warning("LLM æä¾›è€…æœªé…ç½®ï¼Œæ»šåŠ¨æ‘˜è¦é™çº§åˆ°æˆªæ–­å‹ç¼©ã€‚")
                return await self._fallback_compress(segments, context)
            raise CompressionError(
                what="æ»šåŠ¨æ‘˜è¦å‹ç¼©å¤±è´¥",
                why="æœªé…ç½® LLM æä¾›è€…ä¸”æœªå¯ç”¨ fallback",
                how="è¯·ä¼ å…¥ LLMProvider å®ä¾‹æˆ–è®¾ç½® enable_fallback=True",
            )

        # è°ƒç”¨ LLM ç”Ÿæˆ/æ›´æ–°æ‘˜è¦
        was_incremental = self._previous_summary is not None
        try:
            summary_text = await self._generate_rolling_summary(older_segments)
        except Exception as e:
            if self._enable_fallback:
                logger.warning(f"æ»šåŠ¨æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼š{e}ï¼Œé™çº§åˆ°æˆªæ–­å‹ç¼©ã€‚")
                return await self._fallback_compress(segments, context)
            raise CompressionError(
                what="æ»šåŠ¨æ‘˜è¦ç”Ÿæˆå¤±è´¥", why=str(e),
                how="æ£€æŸ¥ LLM API é…ç½®æˆ–å¯ç”¨ fallback",
            ) from e

        # æ›´æ–°æ»šåŠ¨çŠ¶æ€
        self._previous_summary = summary_text

        summary_segment = Segment(
            type=SegmentType.SUMMARY, content=summary_text, role="assistant",
            provenance=Provenance(
                source_id=f"rolling_summary_{parent_ids[0] if parent_ids else 'empty'}",
                source_type=SourceType.COMPRESSION,
                parent_segment_ids=[seg.id for seg in older_segments],
                compression_method=self.name,
            ),
            token_count=None,
        )

        result_segments = [summary_segment] + list(recent_segments)
        estimated_tokens = len(summary_text) // 4 + sum(
            seg.token_count or 0 for seg in recent_segments
        )

        return CompressionResult(
            compressed_segments=result_segments,
            original_token_count=original_tokens,
            compressed_token_count=estimated_tokens,
            method=self.name, parent_segment_ids=parent_ids,
            metadata={
                "rolling_state": "incremental" if was_incremental else "initial",
                "older_count": len(older_segments),
                "recent_count": len(recent_segments),
            },
        )

    async def _generate_rolling_summary(self, segments: list[Segment]) -> str:
        """ç”Ÿæˆæˆ–å¢é‡æ›´æ–°æ»šåŠ¨æ‘˜è¦ï¼ˆæœ‰ _previous_summary æ—¶æ„é€ å¢é‡ Promptï¼‰ã€‚"""
        new_content = "\n\n".join(
            f"[{seg.type.value.upper()}] {seg.content}" for seg in segments
        )

        if self._previous_summary:
            prompt = (
                f"ä½ æ˜¯ä¸€ä¸ªå¯¹è¯æ‘˜è¦åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯æ›´æ–°æ‘˜è¦ã€‚\n\n"
                f"ä¸Šä¸€è½®æ‘˜è¦ï¼š\n{self._previous_summary}\n\n"
                f"æ–°æ¶ˆæ¯ï¼š\n{new_content}\n\n"
                f"è¯·ç”Ÿæˆæ›´æ–°åçš„æ‘˜è¦ï¼Œä¿ç•™æ‰€æœ‰å…³é”®ä¿¡æ¯ï¼ˆ2-5 æ¡è¦ç‚¹ï¼‰ï¼š\n"
            )
        else:
            prompt = (
                f"è¯·æ€»ç»“ä»¥ä¸‹å¯¹è¯å†…å®¹çš„å…³é”®è¦ç‚¹ï¼Œä¿ç•™æ ¸å¿ƒä¿¡æ¯ã€‚\n"
                f"è¾“å‡ºæ ¼å¼ï¼šç®€æ´çš„è¦ç‚¹åˆ—è¡¨ï¼ˆ2-5 æ¡ï¼‰ã€‚\n\n"
                f"å†…å®¹ï¼š\n{new_content}\n\næ€»ç»“ï¼š\n"
            )

        if self._provider is None:
            raise ValueError("LLM æä¾›è€…æœªé…ç½®")

        summary = await self._provider.generate(
            prompt, max_tokens=self._max_summary_tokens
        )
        return summary.strip()

    async def _fallback_compress(
        self, segments: list[Segment], context: CompressContext
    ) -> CompressionResult:
        """é™çº§åˆ°æˆªæ–­å‹ç¼©ã€‚"""
        return await self._fallback_compressor.compress(segments, context)
