"""
åæ¨¡å¼æ£€æµ‹è§„åˆ™å®ç°ã€‚

â†’ 6.7 åæ¨¡å¼æ£€æµ‹ä¸è¯Šæ–­

æœ¬æ¨¡å—å®ç° 10 ä¸ªæ ¸å¿ƒåæ¨¡å¼æ£€æµ‹è§„åˆ™ï¼š

**CRITICAL çº§åˆ«**ï¼ˆå¯èƒ½å¯¼è‡´åŠŸèƒ½å¼‚å¸¸ï¼‰ï¼š
1. MissingTokenCountRule â€” æ£€æµ‹ token_count ç¼ºå¤±
2. NamespaceLeakageRule â€” æ£€æµ‹å‘½åç©ºé—´éš”ç¦»å¤±è´¥
3. CircularDependencyRule â€” æ£€æµ‹å¾ªç¯ä¾èµ–

**WARNING çº§åˆ«**ï¼ˆæ•ˆç‡æˆ–æˆæœ¬é—®é¢˜ï¼‰ï¼š
4. OveruseCriticalRule â€” æ£€æµ‹ CRITICAL ä¼˜å…ˆçº§æ»¥ç”¨
5. RigidBudgetTooLargeRule â€” æ£€æµ‹åˆšæ€§é¢„ç®—è¿‡å¤§
6. ExpiredDataRule â€” æ£€æµ‹è¿‡æœŸæ•°æ®æœªæ¸…ç†
7. OverCompressionRule â€” æ£€æµ‹è¿‡åº¦å‹ç¼©

**INFO çº§åˆ«**ï¼ˆä¼˜åŒ–å»ºè®®ï¼‰ï¼š
8. IneffectiveRoutingRule â€” æ£€æµ‹æ— æ•ˆçš„è·¯ç”±å†³ç­–
9. CacheKeyCollisionRule â€” æ£€æµ‹ç¼“å­˜é”®å†²çªé£é™©
10. UnusedSanitizerRule â€” æ£€æµ‹æœªä½¿ç”¨çš„æ¸…æ´—è§„åˆ™

æ¯ä¸ªè§„åˆ™éƒ½éµå¾ªä¸‰æ®µå¼é”™è¯¯ä¿¡æ¯ï¼šWhatï¼ˆé—®é¢˜æ˜¯ä»€ä¹ˆï¼‰+ Whyï¼ˆä¸ºä»€ä¹ˆï¼‰+ Howï¼ˆå¦‚ä½•ä¿®å¤ï¼‰ã€‚
"""

from __future__ import annotations

from datetime import datetime, timezone

from context_forge.antipattern.base import (
    AntiPatternSeverity,
    DetectionContext,
    DetectionResult,
)
from context_forge.models.audit import DecisionType
from context_forge.models.segment import Priority, SegmentType

# ============================================================
# CRITICAL çº§åˆ«è§„åˆ™ï¼ˆåŠŸèƒ½å¼‚å¸¸é£é™©ï¼‰
# ============================================================


class MissingTokenCountRule:
    """
    æ£€æµ‹ token_count ç¼ºå¤±çš„ Segmentã€‚

    â†’ 6.7.2 Dirty Context åæ¨¡å¼

    # [Design Decision] token_count æ˜¯é¢„ç®—åˆ†é…çš„æ ¸å¿ƒä¾æ®ã€‚
    # å¦‚æœ Segment ç¼ºå¤± token_countï¼ŒBudget Manager æ— æ³•æ­£ç¡®åˆ†é…é¢„ç®—ï¼Œ
    # å¯èƒ½å¯¼è‡´çª—å£æº¢å‡ºæˆ–é¢„ç®—åˆ†é…ä¸å…¬ã€‚

    ä¸¥é‡æ€§: CRITICAL
    """

    @property
    def name(self) -> str:
        return "MissingTokenCountRule"

    @property
    def severity(self) -> AntiPatternSeverity:
        return AntiPatternSeverity.CRITICAL

    def detect(self, context: DetectionContext) -> list[DetectionResult]:
        """æ£€æµ‹ç¼ºå¤± token_count çš„ Segmentã€‚"""
        missing_segments = [
            seg for seg in context.segments
            if seg.token_count is None or seg.token_count == 0
        ]

        if not missing_segments:
            return []

        ids = [seg.id for seg in missing_segments]
        missing_count = len(missing_segments)
        total_count = len(context.segments)

        return [DetectionResult(
            rule_name=self.name,
            severity=self.severity,
            title="æ£€æµ‹åˆ°ç¼ºå¤± Token è®¡æ•°çš„ Segment",
            message=f"åœ¨ {total_count} ä¸ª Segment ä¸­ï¼Œæœ‰ {missing_count} ä¸ªç¼ºå¤± token_count å­—æ®µã€‚",
            why=(
                "Token è®¡æ•°æ˜¯é¢„ç®—åˆ†é…çš„æ ¸å¿ƒä¾æ®ã€‚ç¼ºå¤± token_count ä¼šå¯¼è‡´ Budget Manager "
                "æ— æ³•æ­£ç¡®ä¼°ç®—çª—å£å ç”¨ï¼Œå¯èƒ½å¼•å‘çª—å£æº¢å‡ºæˆ–é¢„ç®—åˆ†é…ä¸å…¬ã€‚"
            ),
            how=(
                "ç¡®ä¿æ‰€æœ‰ Segment åœ¨è¿›å…¥ Pipeline å‰ç»è¿‡ NormalizeStage é˜¶æ®µï¼Œ"
                "è¯¥é˜¶æ®µä¼šè‡ªåŠ¨å¡«å…… token_countã€‚å¦‚æœæ‰‹åŠ¨æ„å»º Segmentï¼Œ"
                "è¯·è°ƒç”¨ tokenizer.count_tokens() å¡«å……æ­¤å­—æ®µã€‚"
            ),
            segment_ids=ids,
            metadata={
                "missing_count": missing_count,
                "total_count": total_count,
                "missing_ratio": f"{missing_count / total_count:.1%}",
            },
        )]


class NamespaceLeakageRule:
    """
    æ£€æµ‹å‘½åç©ºé—´éš”ç¦»å¤±è´¥ã€‚

    â†’ 6.7.3 Context Clash åæ¨¡å¼

    å¤š Agent åœºæ™¯ä¸­ï¼Œä¸åŒ Agent çš„ä¸Šä¸‹æ–‡åº”é€šè¿‡å‘½åç©ºé—´éš”ç¦»ã€‚
    å¦‚æœå‘ç°æœ¬åº”å±äºå…¶ä»–å‘½åç©ºé—´çš„ Segment å‡ºç°åœ¨å½“å‰ä¸Šä¸‹æ–‡ä¸­ï¼Œ
    è¯´æ˜å‘½åç©ºé—´éš”ç¦»æœºåˆ¶å¤±è´¥ã€‚

    ä¸¥é‡æ€§: CRITICAL
    """

    @property
    def name(self) -> str:
        return "NamespaceLeakageRule"

    @property
    def severity(self) -> AntiPatternSeverity:
        return AntiPatternSeverity.CRITICAL

    def detect(self, context: DetectionContext) -> list[DetectionResult]:
        """æ£€æµ‹å‘½åç©ºé—´æ³„æ¼ã€‚"""
        # è·å–ç›®æ ‡å‘½åç©ºé—´ï¼ˆä» context.config æˆ–é»˜è®¤ä¸º "default"ï¼‰
        target_namespace = context.config.get("target_namespace", "default")

        # æŸ¥æ‰¾ä¸å±äºç›®æ ‡å‘½åç©ºé—´çš„ Segment
        leaked_segments = [
            seg for seg in context.segments
            if seg.control and seg.control.namespace
            and seg.control.namespace != target_namespace
            and seg.control.namespace != "global"  # global å‘½åç©ºé—´å…è®¸è·¨è¶Š
        ]

        if not leaked_segments:
            return []

        # æŒ‰æ¥æºå‘½åç©ºé—´åˆ†ç»„
        from collections import defaultdict
        by_namespace: dict[str, list[str]] = defaultdict(list)
        for seg in leaked_segments:
            ns = seg.control.namespace if seg.control else "unknown"
            by_namespace[ns].append(seg.id)

        ids = [seg.id for seg in leaked_segments]
        leaked_count = len(leaked_segments)

        namespace_summary = ", ".join(
            f"{ns}({len(ids)} ä¸ª)" for ns, ids in by_namespace.items()
        )

        return [DetectionResult(
            rule_name=self.name,
            severity=self.severity,
            title="æ£€æµ‹åˆ°å‘½åç©ºé—´æ³„æ¼",
            message=(
                f"ç›®æ ‡å‘½åç©ºé—´ä¸º '{target_namespace}'ï¼Œä½†å‘ç° {leaked_count} ä¸ª "
                f"Segment å±äºå…¶ä»–å‘½åç©ºé—´ï¼š{namespace_summary}ã€‚"
            ),
            why=(
                "å‘½åç©ºé—´ç”¨äºéš”ç¦»å¤š Agent çš„ä¸Šä¸‹æ–‡ã€‚å‘½åç©ºé—´æ³„æ¼ä¼šå¯¼è‡´ Agent A çš„ç§æœ‰ä¿¡æ¯ "
                "æ³„æ¼åˆ° Agent B çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œå¼•å‘å®‰å…¨é£é™©æˆ–é€»è¾‘æ··ä¹±ã€‚"
            ),
            how=(
                "æ£€æŸ¥ Pipeline çš„ IsolateStage æ˜¯å¦æ­£ç¡®é…ç½®ã€‚ç¡®ä¿åœ¨å¤š Agent åœºæ™¯ä¸­ "
                "ä¸ºæ¯ä¸ª Agent æŒ‡å®šç‹¬ç«‹çš„å‘½åç©ºé—´ï¼Œå¹¶åœ¨ build() æ—¶ä¼ å…¥æ­£ç¡®çš„ "
                "target_namespace å‚æ•°ã€‚"
            ),
            segment_ids=ids,
            metadata={
                "target_namespace": target_namespace,
                "leaked_namespaces": dict(by_namespace),
                "leaked_count": leaked_count,
            },
        )]


class CircularDependencyRule:
    """
    æ£€æµ‹ Segment ä¹‹é—´çš„å¾ªç¯ä¾èµ–ã€‚

    â†’ 6.7.3 Context Clash åæ¨¡å¼

    å¦‚æœ Segment A çš„ depends_on åŒ…å« Bï¼Œè€Œ B çš„ depends_on åŒ…å« Aï¼Œ
    å½¢æˆå¾ªç¯ä¾èµ–ï¼Œæµæ°´çº¿æ— æ³•ç¡®å®šæ­£ç¡®çš„å¤„ç†é¡ºåºã€‚

    ä¸¥é‡æ€§: CRITICAL
    """

    @property
    def name(self) -> str:
        return "CircularDependencyRule"

    @property
    def severity(self) -> AntiPatternSeverity:
        return AntiPatternSeverity.CRITICAL

    def detect(self, context: DetectionContext) -> list[DetectionResult]:
        """æ£€æµ‹å¾ªç¯ä¾èµ–ã€‚"""
        # æ„å»ºä¾èµ–å›¾
        # æ³¨æ„ï¼šControlFlags å½“å‰æ²¡æœ‰ depends_on å­—æ®µï¼Œæ­¤è§„åˆ™æš‚æ—¶ä¸ç”Ÿæ•ˆ
        # ğŸ­ ç”Ÿäº§æç¤ºï¼šå¦‚æœéœ€è¦ä¾èµ–ç®¡ç†ï¼Œéœ€è¦åœ¨ ControlFlags ä¸­æ·»åŠ  depends_on å­—æ®µ
        graph: dict[str, set[str]] = {}
        for seg in context.segments:
            if seg.control and hasattr(seg.control, "depends_on") and seg.control.depends_on:
                graph[seg.id] = set(seg.control.depends_on)
            else:
                graph[seg.id] = set()

        # DFS æ£€æµ‹ç¯
        def has_cycle(node: str, visited: set[str], rec_stack: set[str]) -> list[str] | None:
            visited.add(node)
            rec_stack.add(node)

            for neighbor in graph.get(node, set()):
                if neighbor not in visited:
                    cycle = has_cycle(neighbor, visited, rec_stack)
                    if cycle:
                        return [node] + cycle
                elif neighbor in rec_stack:
                    # æ‰¾åˆ°ç¯
                    return [node, neighbor]

            rec_stack.remove(node)
            return None

        # æ£€æµ‹æ‰€æœ‰èŠ‚ç‚¹
        visited: set[str] = set()
        cycles: list[list[str]] = []

        for node in graph:
            if node not in visited:
                cycle = has_cycle(node, visited, set())
                if cycle:
                    cycles.append(cycle)

        if not cycles:
            return []

        # åªæŠ¥å‘Šç¬¬ä¸€ä¸ªç¯ï¼ˆé¿å…é‡å¤ï¼‰
        first_cycle = cycles[0]
        cycle_str = " -> ".join(first_cycle[:4])
        if len(first_cycle) > 4:
            cycle_str += f" -> ... ({len(first_cycle)} ä¸ª Segment)"

        return [DetectionResult(
            rule_name=self.name,
            severity=self.severity,
            title="æ£€æµ‹åˆ° Segment å¾ªç¯ä¾èµ–",
            message=f"å‘ç° {len(cycles)} ä¸ªå¾ªç¯ä¾èµ–é“¾ã€‚ç¤ºä¾‹: {cycle_str}",
            why=(
                "å¾ªç¯ä¾èµ–ä¼šå¯¼è‡´æµæ°´çº¿æ— æ³•ç¡®å®š Segment çš„å¤„ç†é¡ºåºï¼Œ"
                "å¯èƒ½å¼•å‘æ­»é”æˆ–æ— é™å¾ªç¯ã€‚"
            ),
            how=(
                "æ£€æŸ¥ Segment çš„ control.depends_on å­—æ®µï¼Œç§»é™¤å¾ªç¯å¼•ç”¨ã€‚"
                "å¦‚æœ A å’Œ B éœ€è¦ç›¸äº’åä½œï¼Œè€ƒè™‘å¼•å…¥ç¬¬ä¸‰ä¸ª Coordinator Segment "
                "æ¥æ‰“ç ´å¾ªç¯ã€‚"
            ),
            segment_ids=first_cycle,
            metadata={
                "cycle_count": len(cycles),
                "first_cycle": first_cycle,
            },
        )]


# ============================================================
# WARNING çº§åˆ«è§„åˆ™ï¼ˆæ•ˆç‡æˆ–æˆæœ¬é—®é¢˜ï¼‰
# ============================================================


class OveruseCriticalRule:
    """
    æ£€æµ‹ CRITICAL ä¼˜å…ˆçº§æ»¥ç”¨ã€‚

    â†’ 6.7.2 All-in-Context åæ¨¡å¼

    å¦‚æœè¶…è¿‡ 50% çš„ Segment è¢«æ ‡è®°ä¸º CRITICALï¼Œè¯´æ˜ä¼˜å…ˆçº§è®¾ç½®å¤±å½“ã€‚
    CRITICAL åº”ä»…ç”¨äºç³»ç»Ÿæç¤ºã€Schema ç­‰ä¸å¯ä¸¢å¼ƒçš„å†…å®¹ã€‚

    ä¸¥é‡æ€§: WARNING
    """

    @property
    def name(self) -> str:
        return "OveruseCriticalRule"

    @property
    def severity(self) -> AntiPatternSeverity:
        return AntiPatternSeverity.WARNING

    def detect(self, context: DetectionContext) -> list[DetectionResult]:
        """æ£€æµ‹ CRITICAL ä¼˜å…ˆçº§æ»¥ç”¨ã€‚"""
        if not context.segments:
            return []

        critical_segments = [
            seg for seg in context.segments
            if seg.priority == Priority.CRITICAL
        ]

        critical_ratio = len(critical_segments) / len(context.segments)
        threshold = context.config.get("critical_ratio_threshold", 0.5)

        if critical_ratio <= threshold:
            return []

        ids = [seg.id for seg in critical_segments]

        return [DetectionResult(
            rule_name=self.name,
            severity=self.severity,
            title="æ£€æµ‹åˆ° CRITICAL ä¼˜å…ˆçº§æ»¥ç”¨",
            message=(
                f"{len(critical_segments)}/{len(context.segments)} "
                f"({critical_ratio:.1%}) çš„ Segment è¢«æ ‡è®°ä¸º CRITICALï¼Œ"
                f"è¶…è¿‡é˜ˆå€¼ {threshold:.1%}ã€‚"
            ),
            why=(
                "CRITICAL ä¼˜å…ˆçº§è¡¨ç¤º'ä¸å¯ä¸¢å¼ƒ'ï¼Œåº”ä»…ç”¨äºç³»ç»Ÿæç¤ºã€Schema ç­‰æ ¸å¿ƒå†…å®¹ã€‚"
                "è¿‡åº¦ä½¿ç”¨ CRITICAL ä¼šå¯¼è‡´ Budget Manager å¤±å»å¼¹æ€§è°ƒèŠ‚èƒ½åŠ›ï¼Œ"
                "åœ¨é¢„ç®—ä¸è¶³æ—¶æ— æ³•åŠ¨æ€è£å‰ªå†…å®¹ã€‚"
            ),
            how=(
                "å®¡æŸ¥ Segment çš„ä¼˜å…ˆçº§è®¾ç½®ã€‚å°†éæ ¸å¿ƒå†…å®¹ï¼ˆå¦‚ RAG ç‰‡æ®µã€å¯¹è¯å†å²ï¼‰"
                "è°ƒæ•´ä¸º MEDIUM æˆ– LOW ä¼˜å…ˆçº§ï¼Œä»…ä¿ç•™ç³»ç»Ÿæç¤ºå’Œ Schema ä¸º CRITICALã€‚"
            ),
            segment_ids=ids[:10],  # ä»…æ˜¾ç¤ºå‰ 10 ä¸ª
            metadata={
                "critical_count": len(critical_segments),
                "total_count": len(context.segments),
                "critical_ratio": f"{critical_ratio:.1%}",
                "threshold": f"{threshold:.1%}",
            },
        )]


class RigidBudgetTooLargeRule:
    """
    æ£€æµ‹åˆšæ€§é¢„ç®—å æ¯”è¿‡å¤§ã€‚

    â†’ 6.7.2 All-in-Context åæ¨¡å¼

    å¦‚æœåˆšæ€§é¢„ç®—ï¼ˆCRITICAL ä¼˜å…ˆçº§ Segmentï¼‰å æ€»é¢„ç®—çš„ 70% ä»¥ä¸Šï¼Œ
    å¼¹æ€§é¢„ç®—ç©ºé—´è¿‡å°ï¼Œæ— æ³•åº”å¯¹åŠ¨æ€åœºæ™¯ã€‚

    ä¸¥é‡æ€§: WARNING
    """

    @property
    def name(self) -> str:
        return "RigidBudgetTooLargeRule"

    @property
    def severity(self) -> AntiPatternSeverity:
        return AntiPatternSeverity.WARNING

    def detect(self, context: DetectionContext) -> list[DetectionResult]:
        """æ£€æµ‹åˆšæ€§é¢„ç®—å æ¯”ã€‚"""
        if not context.budget_allocation or not context.budget_policy:
            return []

        allocation = context.budget_allocation
        policy = context.budget_policy

        # è®¡ç®—åˆšæ€§é¢„ç®—å æ¯”
        if allocation.content_budget == 0:
            return []

        rigid_ratio = allocation.rigid_used / allocation.content_budget
        threshold = context.config.get("rigid_budget_threshold", 0.7)

        if rigid_ratio <= threshold:
            return []

        return [DetectionResult(
            rule_name=self.name,
            severity=self.severity,
            title="æ£€æµ‹åˆ°åˆšæ€§é¢„ç®—å æ¯”è¿‡å¤§",
            message=(
                f"åˆšæ€§é¢„ç®—å ç”¨ {allocation.rigid_used:,} tokensï¼Œ"
                f"å æ€»é¢„ç®—çš„ {rigid_ratio:.1%}ï¼Œè¶…è¿‡é˜ˆå€¼ {threshold:.1%}ã€‚"
            ),
            why=(
                "åˆšæ€§é¢„ç®—ç”¨äºä¿éšœ CRITICAL ä¼˜å…ˆçº§çš„ Segmentã€‚å æ¯”è¿‡å¤§ä¼šå‹ç¼©å¼¹æ€§ç©ºé—´ï¼Œ"
                "å¯¼è‡´ RAG ç‰‡æ®µã€å¯¹è¯å†å²ç­‰åŠ¨æ€å†…å®¹æ— æ³•è·å¾—è¶³å¤Ÿé…é¢ï¼Œ"
                "å½±å“ä¸Šä¸‹æ–‡çš„ä¸°å¯Œåº¦å’Œå¤šæ ·æ€§ã€‚"
            ),
            how=(
                "å‡å°‘ CRITICAL ä¼˜å…ˆçº§ Segment çš„æ•°é‡æˆ–é•¿åº¦ã€‚å°†å¯å‹ç¼©çš„ç³»ç»Ÿæç¤º "
                "æ”¹ä¸º HIGH ä¼˜å…ˆçº§ï¼Œæˆ–å¯ç”¨å‹ç¼©åŠŸèƒ½å‡å°‘åˆšæ€§åŒºé—´å ç”¨ã€‚"
            ),
            segment_ids=[],
            metadata={
                "rigid_used": allocation.rigid_used,
                "content_budget": allocation.content_budget,
                "rigid_ratio": f"{rigid_ratio:.1%}",
                "threshold": f"{threshold:.1%}",
                "elastic_available": allocation.content_budget - allocation.rigid_used,
            },
        )]


class ExpiredDataRule:
    """
    æ£€æµ‹è¿‡æœŸæ•°æ®æœªæ¸…ç†ã€‚

    â†’ 6.7.4 Context Confusion åæ¨¡å¼

    å¦‚æœ Segment çš„ created_at è·ä»Šè¶…è¿‡ 30 å¤©ï¼ˆå¯é…ç½®ï¼‰ï¼Œ
    è¯´æ˜å¯èƒ½å­˜åœ¨è¿‡æœŸæ•°æ®æœªè¢« TTL æœºåˆ¶æ¸…ç†ã€‚

    ä¸¥é‡æ€§: WARNING
    """

    @property
    def name(self) -> str:
        return "ExpiredDataRule"

    @property
    def severity(self) -> AntiPatternSeverity:
        return AntiPatternSeverity.WARNING

    def detect(self, context: DetectionContext) -> list[DetectionResult]:
        """æ£€æµ‹è¿‡æœŸæ•°æ®ã€‚"""
        now = datetime.now(timezone.utc)
        ttl_days = context.config.get("ttl_days_threshold", 30)

        expired_segments = []
        for seg in context.segments:
            if seg.metadata and seg.metadata.injected_at:
                age_days = (now - seg.metadata.injected_at).days
                if age_days > ttl_days:
                    expired_segments.append((seg, age_days))

        if not expired_segments:
            return []

        ids = [seg.id for seg, _ in expired_segments]
        max_age = max(age for _, age in expired_segments)

        return [DetectionResult(
            rule_name=self.name,
            severity=self.severity,
            title="æ£€æµ‹åˆ°è¿‡æœŸæ•°æ®æœªæ¸…ç†",
            message=(
                f"å‘ç° {len(expired_segments)} ä¸ª Segment çš„å¹´é¾„è¶…è¿‡ {ttl_days} å¤©ï¼Œ"
                f"æœ€æ—§çš„è¾¾åˆ° {max_age} å¤©ã€‚"
            ),
            why=(
                "è¿‡æœŸæ•°æ®å ç”¨ä¸Šä¸‹æ–‡çª—å£ï¼Œé™ä½æ–°é²œä¿¡æ¯çš„å æ¯”ã€‚"
                "é•¿æ—¶é—´æœªæ›´æ–°çš„æ•°æ®å¯èƒ½å·²è¿‡æ—¶ï¼Œå½±å“æ¨¡å‹çš„å›ç­”å‡†ç¡®æ€§ã€‚"
            ),
            how=(
                "å¯ç”¨ TTLï¼ˆTime-To-Liveï¼‰æœºåˆ¶ï¼Œåœ¨ Rerank é˜¶æ®µè‡ªåŠ¨è¿‡æ»¤è¿‡æœŸ Segmentã€‚"
                "æˆ–åœ¨åº”ç”¨å±‚å®šæœŸæ¸…ç†ç¼“å­˜ä¸­çš„è¿‡æœŸæ•°æ®ã€‚"
            ),
            segment_ids=ids[:10],
            metadata={
                "expired_count": len(expired_segments),
                "ttl_days_threshold": ttl_days,
                "max_age_days": max_age,
            },
        )]


class OverCompressionRule:
    """
    æ£€æµ‹è¿‡åº¦å‹ç¼©ã€‚

    â†’ 6.7.2 All-in-Context åæ¨¡å¼ï¼ˆåå‘ï¼‰

    å¦‚æœå‹ç¼©åçš„ Segment é•¿åº¦ < åŸé•¿åº¦çš„ 10%ï¼Œè¯´æ˜å‹ç¼©ç‡è¿‡é«˜ï¼Œ
    å¯èƒ½ä¸¢å¤±å…³é”®ä¿¡æ¯ã€‚

    ä¸¥é‡æ€§: WARNING
    """

    @property
    def name(self) -> str:
        return "OverCompressionRule"

    @property
    def severity(self) -> AntiPatternSeverity:
        return AntiPatternSeverity.WARNING

    def detect(self, context: DetectionContext) -> list[DetectionResult]:
        """æ£€æµ‹è¿‡åº¦å‹ç¼©ã€‚"""
        # ä»å®¡è®¡æ—¥å¿—ä¸­æŸ¥æ‰¾å‹ç¼©æ“ä½œ
        over_compressed = []
        threshold = context.config.get("compression_ratio_threshold", 0.1)

        for entry in context.audit_log:
            if entry.decision == DecisionType.COMPRESS:
                # ä» metadata ä¸­è·å–å‹ç¼©å‰åçš„ token æ•°
                original_tokens = entry.metadata.get("original_tokens", 0)
                compressed_tokens = entry.metadata.get("compressed_tokens", 0)

                if original_tokens > 0:
                    ratio = compressed_tokens / original_tokens
                    if ratio < threshold:
                        over_compressed.append((entry, ratio))

        if not over_compressed:
            return []

        ids = [entry.segment_id for entry, _ in over_compressed]
        min_ratio = min(ratio for _, ratio in over_compressed)

        return [DetectionResult(
            rule_name=self.name,
            severity=self.severity,
            title="æ£€æµ‹åˆ°è¿‡åº¦å‹ç¼©",
            message=(
                f"å‘ç° {len(over_compressed)} ä¸ª Segment çš„å‹ç¼©ç‡ä½äº {threshold:.1%}ï¼Œ"
                f"æœ€ä½è¾¾åˆ° {min_ratio:.1%}ã€‚"
            ),
            why=(
                "è¿‡åº¦å‹ç¼©ä¼šä¸¢å¤±å…³é”®ç»†èŠ‚ï¼Œå¯¼è‡´æ¨¡å‹ç†è§£ä¸å®Œæ•´ã€‚"
                "è™½ç„¶èŠ‚çœäº† Tokenï¼Œä½†å¯èƒ½å½±å“å›ç­”è´¨é‡ã€‚"
            ),
            how=(
                "è°ƒæ•´å‹ç¼©å™¨çš„é…ç½®ï¼Œå¢åŠ  min_segment_tokens æˆ–é™ä½ saturation_triggerã€‚"
                "å¯¹äºé‡è¦çš„ Segmentï¼Œè®¾ç½® control.compressible=False ç¦æ­¢å‹ç¼©ã€‚"
            ),
            segment_ids=ids[:10],
            metadata={
                "over_compressed_count": len(over_compressed),
                "compression_ratio_threshold": f"{threshold:.1%}",
                "min_compression_ratio": f"{min_ratio:.1%}",
            },
        )]


# ============================================================
# INFO çº§åˆ«è§„åˆ™ï¼ˆä¼˜åŒ–å»ºè®®ï¼‰
# ============================================================


class IneffectiveRoutingRule:
    """
    æ£€æµ‹æ— æ•ˆçš„è·¯ç”±å†³ç­–ã€‚

    â†’ 6.7.4 Context Confusion åæ¨¡å¼

    å¦‚æœè·¯ç”±å™¨é€‰æ‹©äº†ä¸€ä¸ªæ¨¡å‹ï¼Œä½†å®é™…ä½¿ç”¨çš„çª—å£å¤§å°ä¸ç›®æ ‡æ¨¡å‹çš„çª—å£å·®å¼‚å¾ˆå°ï¼Œ
    è¯´æ˜è·¯ç”±å†³ç­–å¯èƒ½æ— æ•ˆï¼ˆæ²¡æœ‰å¸¦æ¥å®è´¨æ€§çš„ä¼˜åŒ–ï¼‰ã€‚

    ä¸¥é‡æ€§: INFO
    """

    @property
    def name(self) -> str:
        return "IneffectiveRoutingRule"

    @property
    def severity(self) -> AntiPatternSeverity:
        return AntiPatternSeverity.INFO

    def detect(self, context: DetectionContext) -> list[DetectionResult]:
        """æ£€æµ‹æ— æ•ˆçš„è·¯ç”±å†³ç­–ã€‚"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†è·¯ç”±
        if not context.config.get("routing_enabled", False):
            return []

        # æ£€æŸ¥æ˜¯å¦æœ‰è·¯ç”±å†³ç­–ï¼ˆéœ€ä» metadata ä¼ å…¥ï¼‰
        routing_decision = context.config.get("routing_decision")
        if not routing_decision:
            return []

        # æ£€æŸ¥è·¯ç”±å‰åçš„çª—å£å¤§å°å·®å¼‚
        original_window = context.config.get("original_window_size", 0)
        selected_window = context.config.get("selected_window_size", 0)

        if original_window == 0 or selected_window == 0:
            return []

        diff_ratio = abs(selected_window - original_window) / original_window
        threshold = context.config.get("routing_effectiveness_threshold", 0.1)

        if diff_ratio >= threshold:
            return []

        return [DetectionResult(
            rule_name=self.name,
            severity=self.severity,
            title="æ£€æµ‹åˆ°æ— æ•ˆçš„è·¯ç”±å†³ç­–",
            message=(
                f"è·¯ç”±å™¨é€‰æ‹©äº†çª—å£å¤§å°ä¸º {selected_window:,} çš„æ¨¡å‹ï¼Œ"
                f"ä¸åŸæ¨¡å‹çª—å£ {original_window:,} çš„å·®å¼‚ä»… {diff_ratio:.1%}ã€‚"
            ),
            why=(
                "è·¯ç”±çš„ç›®æ ‡æ˜¯æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©æ›´åˆé€‚çš„æ¨¡å‹ï¼ˆæ›´å¤§æˆ–æ›´å°çš„çª—å£ï¼‰ã€‚"
                "å¦‚æœçª—å£å·®å¼‚å¾ˆå°ï¼Œè·¯ç”±å†³ç­–æ²¡æœ‰å¸¦æ¥å®è´¨æ€§çš„ä¼˜åŒ–ï¼Œåè€Œå¢åŠ äº†å¤æ‚åº¦ã€‚"
            ),
            how=(
                "æ£€æŸ¥è·¯ç”±è§„åˆ™é…ç½®ï¼Œç¡®ä¿å¤æ‚åº¦é˜ˆå€¼è®¾ç½®åˆç†ã€‚"
                "å¦‚æœå¤§å¤šæ•°ä»»åŠ¡ä¸éœ€è¦è·¯ç”±ï¼Œè€ƒè™‘ç¦ç”¨è·¯ç”±åŠŸèƒ½ä»¥ç®€åŒ–ç³»ç»Ÿã€‚"
            ),
            segment_ids=[],
            metadata={
                "original_window_size": original_window,
                "selected_window_size": selected_window,
                "diff_ratio": f"{diff_ratio:.1%}",
                "threshold": f"{threshold:.1%}",
            },
        )]


class CacheKeyCollisionRule:
    """
    æ£€æµ‹ç¼“å­˜é”®å†²çªé£é™©ã€‚

    â†’ 6.7.4 Context Confusion åæ¨¡å¼

    å¦‚æœå¤šä¸ª Segment å…·æœ‰ç›¸åŒçš„ provenance.source_idï¼Œ
    å¯èƒ½å¯¼è‡´ç¼“å­˜é”®å†²çªï¼ˆç‰¹åˆ«æ˜¯åœ¨è¯­ä¹‰ç¼“å­˜ä¸­ï¼‰ã€‚

    ä¸¥é‡æ€§: INFO
    """

    @property
    def name(self) -> str:
        return "CacheKeyCollisionRule"

    @property
    def severity(self) -> AntiPatternSeverity:
        return AntiPatternSeverity.INFO

    def detect(self, context: DetectionContext) -> list[DetectionResult]:
        """æ£€æµ‹ç¼“å­˜é”®å†²çªã€‚"""
        # æŒ‰ source_id åˆ†ç»„
        from collections import defaultdict
        by_source_id: dict[str, list[str]] = defaultdict(list)

        for seg in context.segments:
            if seg.provenance and seg.provenance.source_id:
                by_source_id[seg.provenance.source_id].append(seg.id)

        # æŸ¥æ‰¾é‡å¤çš„ source_id
        collisions = {
            source_id: seg_ids
            for source_id, seg_ids in by_source_id.items()
            if len(seg_ids) > 1
        }

        if not collisions:
            return []

        total_collisions = sum(len(ids) for ids in collisions.values())
        collision_examples = list(collisions.items())[:3]
        examples_str = ", ".join(
            f"{source_id}({len(ids)} ä¸ª)" for source_id, ids in collision_examples
        )

        return [DetectionResult(
            rule_name=self.name,
            severity=self.severity,
            title="æ£€æµ‹åˆ°ç¼“å­˜é”®å†²çªé£é™©",
            message=(
                f"å‘ç° {len(collisions)} ä¸ª source_id è¢«å¤šä¸ª Segment å…±äº«ï¼Œ"
                f"æ¶‰åŠ {total_collisions} ä¸ª Segmentã€‚ç¤ºä¾‹: {examples_str}"
            ),
            why=(
                "source_id ç”¨äºç”Ÿæˆç¼“å­˜é”®ã€‚å¦‚æœå¤šä¸ª Segment å…±äº«åŒä¸€ä¸ª source_idï¼Œ"
                "å¯èƒ½å¯¼è‡´ç¼“å­˜å‘½ä¸­é”™è¯¯çš„å†…å®¹ï¼Œæˆ–ç¼“å­˜å¤±æ•ˆé€»è¾‘å¼‚å¸¸ã€‚"
            ),
            how=(
                "ç¡®ä¿æ¯ä¸ª Segment çš„ provenance.source_id å”¯ä¸€ã€‚"
                "å¯ä»¥åœ¨ source_id ä¸­åŠ å…¥æ—¶é—´æˆ³æˆ–éšæœºåç¼€ï¼ˆå¦‚ 'doc_123_v2'ï¼‰ã€‚"
            ),
            segment_ids=[],
            metadata={
                "collision_count": len(collisions),
                "total_segments_affected": total_collisions,
                "examples": {k: len(v) for k, v in collision_examples},
            },
        )]


class UnusedSanitizerRule:
    """
    æ£€æµ‹æœªä½¿ç”¨çš„æ¸…æ´—è§„åˆ™ã€‚

    â†’ 6.7.2 Dirty Context åæ¨¡å¼

    å¦‚æœå®¡è®¡æ—¥å¿—ä¸­æ²¡æœ‰ä»»ä½• SANITIZE ç±»å‹çš„å†³ç­–ï¼Œ
    è¯´æ˜æ¸…æ´—è§„åˆ™å¯èƒ½æœªç”Ÿæ•ˆï¼Œæˆ–æ‰€æœ‰å†…å®¹éƒ½æ˜¯å¹²å‡€çš„ã€‚

    ä¸¥é‡æ€§: INFO
    """

    @property
    def name(self) -> str:
        return "UnusedSanitizerRule"

    @property
    def severity(self) -> AntiPatternSeverity:
        return AntiPatternSeverity.INFO

    def detect(self, context: DetectionContext) -> list[DetectionResult]:
        """æ£€æµ‹æœªä½¿ç”¨çš„æ¸…æ´—è§„åˆ™ã€‚"""
        # æ£€æŸ¥å®¡è®¡æ—¥å¿—ä¸­æ˜¯å¦æœ‰ SANITIZE å†³ç­–
        sanitize_entries = [
            entry for entry in context.audit_log
            if entry.decision == DecisionType.SANITIZE
        ]

        if sanitize_entries:
            return []

        # æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·è¾“å…¥æˆ– RAG ç‰‡æ®µï¼ˆè¿™äº›ç±»å‹é€šå¸¸éœ€è¦æ¸…æ´—ï¼‰
        needs_sanitization = [
            seg for seg in context.segments
            if seg.type in (SegmentType.USER, SegmentType.RAG, SegmentType.TOOL_RESULT)
        ]

        if not needs_sanitization:
            # æ²¡æœ‰éœ€è¦æ¸…æ´—çš„å†…å®¹ï¼Œä¸ç®—é—®é¢˜
            return []

        return [DetectionResult(
            rule_name=self.name,
            severity=self.severity,
            title="æ£€æµ‹åˆ°æœªä½¿ç”¨çš„æ¸…æ´—è§„åˆ™",
            message=(
                f"ä¸Šä¸‹æ–‡åŒ…å« {len(needs_sanitization)} ä¸ªéœ€è¦æ¸…æ´—çš„ Segment "
                f"(USER/RAG/TOOL_RESULT)ï¼Œä½†å®¡è®¡æ—¥å¿—ä¸­æ²¡æœ‰ SANITIZE å†³ç­–è®°å½•ã€‚"
            ),
            why=(
                "æ¸…æ´—è§„åˆ™ç”¨äºç§»é™¤ä¸å¯è§å­—ç¬¦ã€HTML æ ‡ç­¾ã€æ£€æµ‹ Injection ç­‰ã€‚"
                "å¦‚æœæ¸…æ´—è§„åˆ™æœªç”Ÿæ•ˆï¼Œå¯èƒ½å­˜åœ¨å®‰å…¨é£é™©æˆ–æ ¼å¼é—®é¢˜ã€‚"
            ),
            how=(
                "æ£€æŸ¥ç­–ç•¥é…ç½®ï¼Œç¡®ä¿ sanitize.unicode_normalizeã€sanitize.strip_html "
                "ç­‰é€‰é¡¹å·²å¯ç”¨ã€‚éªŒè¯ SanitizeStage æ˜¯å¦æ­£ç¡®æ·»åŠ åˆ° Pipeline ä¸­ã€‚"
            ),
            segment_ids=[seg.id for seg in needs_sanitization[:5]],
            metadata={
                "segments_needing_sanitization": len(needs_sanitization),
                "sanitize_entries_in_audit": len(sanitize_entries),
            },
        )]
