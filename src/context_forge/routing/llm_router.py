"""
åŸºäº LLM çš„è·¯ç”±å™¨â€”â€”å¯é€‰çš„é«˜çº§è·¯ç”±å®ç°ã€‚

â†’ 6.6.1 æ„å›¾é©±åŠ¨è·¯ç”±

LLM è·¯ç”±å™¨é€šè¿‡è°ƒç”¨ LLM å¯¹ç”¨æˆ·æŸ¥è¯¢è¿›è¡Œæ„å›¾åˆ†ç±»å’Œå¤æ‚åº¦åˆ¤æ–­ï¼Œ
é€‚ç”¨äºéœ€è¦è¯­ä¹‰ç†è§£çš„è·¯ç”±åœºæ™¯ï¼ˆå¦‚æƒ…æ„Ÿåˆ†æã€ç»†ç²’åº¦åˆ†ç±»ã€å¤šæ„å›¾è¯†åˆ«ï¼‰ã€‚

# [Design Decision] LLM è·¯ç”±å™¨æ˜¯å¯é€‰çš„é«˜çº§åŠŸèƒ½ï¼Œä¸æ˜¯é»˜è®¤è·¯å¾„ï¼š
# 1. éœ€è¦å¤–éƒ¨ä¾èµ– â€” å¿…é¡»æœ‰å¯ç”¨çš„ LLM API
# 2. å¼•å…¥å»¶è¿Ÿ â€” æ¯æ¬¡è·¯ç”±éœ€è¦é¢å¤–çš„ LLM è°ƒç”¨ï¼ˆ50-200msï¼‰
# 3. äº§ç”Ÿæˆæœ¬ â€” æ¯æ¬¡è·¯ç”±æ¶ˆè€— Tokenï¼ˆè™½ç„¶å°‘ï¼Œä½†ç´¯ç§¯èµ·æ¥å¯è§‚ï¼‰
# 4. Fallback æœºåˆ¶ â€” LLM è°ƒç”¨å¤±è´¥æ—¶è‡ªåŠ¨é™çº§åˆ° RuleBasedRouter
#
# é€‚ç”¨åœºæ™¯ï¼šè§„åˆ™å¼•æ“éš¾ä»¥æè¿°çš„è¯­ä¹‰è·¯ç”±ï¼ˆå¦‚"æ£€æµ‹ç”¨æˆ·æ˜¯å¦åœ¨æŠ±æ€¨"ï¼‰ã€‚
# ä¸é€‚ç”¨åœºæ™¯ï¼šæ˜ç¡®çš„å¤æ‚åº¦åˆ†æµã€å…³é”®è¯è·¯ç”±ï¼ˆè§„åˆ™å¼•æ“æ›´å¿«æ›´ä¾¿å®œï¼‰ã€‚

ğŸ­ ç”Ÿäº§æç¤ºï¼š
å®é™…ç”Ÿäº§ä¸­ï¼ŒLLM è·¯ç”±å™¨çš„è°ƒç”¨é€»è¾‘éœ€è¦æ¥å…¥çœŸå®çš„ LLM Providerï¼ˆOpenAI/Anthropicï¼‰ã€‚
æœ¬å®ç°æä¾›äº†æ¥å£å’Œé™çº§æœºåˆ¶ï¼Œå…·ä½“çš„ API è°ƒç”¨éœ€è¦ç”¨æˆ·æ ¹æ®è‡ªå·±çš„ Provider å®ç°ã€‚
"""

from __future__ import annotations

import warnings
from typing import Any

from context_forge.errors.exceptions import RoutingError
from context_forge.models.routing import ComplexityLevel, RoutingDecision
from context_forge.routing.base import RoutingContext
from context_forge.routing.complexity import ComplexityEstimator
from context_forge.routing.rule_based import RuleBasedRouter


class LLMRouter:
    """
    åŸºäº LLM çš„è·¯ç”±å™¨ã€‚

    â†’ 6.6.1 æ„å›¾é©±åŠ¨è·¯ç”±

    é€šè¿‡è°ƒç”¨å°å‹ LLMï¼ˆå¦‚ GPT-4o-miniï¼‰å¯¹æŸ¥è¯¢è¿›è¡Œæ„å›¾åˆ†ç±»ï¼Œ
    ç„¶åæ ¹æ®åˆ†ç±»ç»“æœè·¯ç”±åˆ°åˆé€‚çš„æ¨¡å‹ã€‚

    # [Design Decision] Fallback åˆ° RuleBasedRouterï¼š
    # LLM è°ƒç”¨å¯èƒ½å¤±è´¥ï¼ˆç½‘ç»œé—®é¢˜ã€é…é¢ä¸è¶³ã€Provider é™çº§ï¼‰ï¼Œ
    # è¿™æ—¶ä¸åº”è¯¥è®©æ•´ä¸ªè·¯ç”±å¤±è´¥ï¼Œè€Œæ˜¯é™çº§åˆ°çº¯è§„åˆ™è·¯ç”±ã€‚

    åŸºæœ¬ç”¨æ³•::

        # æ–¹å¼ä¸€ï¼šæä¾›è‡ªå®šä¹‰ LLM è°ƒç”¨å‡½æ•°
        def my_llm_call(prompt: str) -> str:
            # è°ƒç”¨ä½ çš„ LLM Provider
            return openai_client.complete(prompt)

        router = LLMRouter(
            llm_call_fn=my_llm_call,
            fallback_router=RuleBasedRouter(),
        )

        # æ–¹å¼äºŒï¼šä»…ä½¿ç”¨ fallbackï¼ˆå¼€å‘/æµ‹è¯•é˜¶æ®µï¼‰
        router = LLMRouter(
            llm_call_fn=None,  # æ€»æ˜¯é™çº§
            fallback_router=RuleBasedRouter(),
        )
    """

    # â†’ 6.6.1.5 è¯­ä¹‰è·¯ç”±ï¼šLLM åˆ†ç±» Prompt æ¨¡æ¿
    # è¿™ä¸ª Prompt è¦æ±‚ LLM è¾“å‡ºç»“æ„åŒ–çš„ JSONï¼ŒåŒ…å«å¤æ‚åº¦å’Œæ¨ç†è¿‡ç¨‹

    CLASSIFICATION_PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢å¤æ‚åº¦åˆ†ç±»å™¨ã€‚è¯·åˆ†æç”¨æˆ·æŸ¥è¯¢çš„å¤æ‚åº¦ï¼Œå¹¶è¿”å› JSON æ ¼å¼çš„ç»“æœã€‚

å¤æ‚åº¦ç­‰çº§å®šä¹‰ï¼š
- simple: ç®€å•æŸ¥è¯¢ï¼ˆFAQã€ç›´æ¥æŸ¥æ‰¾ã€æ ¼å¼è½¬æ¢ï¼‰
- moderate: ä¸­ç­‰æŸ¥è¯¢ï¼ˆéœ€è¦æ£€ç´¢å’Œç»¼åˆåˆ†æï¼‰
- complex: å¤æ‚æŸ¥è¯¢ï¼ˆéœ€è¦å¤šæ­¥æ¨ç†ã€æ¯”è¾ƒã€åˆ›é€ æ€§æ€è€ƒï¼‰
- expert: ä¸“å®¶çº§æŸ¥è¯¢ï¼ˆéœ€è¦æ·±åº¦æ¨ç†ã€æ•°å­¦è¯æ˜ã€ä»£ç ç”Ÿæˆï¼‰

ç”¨æˆ·æŸ¥è¯¢ï¼š
{query}

è¯·è¿”å› JSONï¼ˆä¸è¦æœ‰å…¶ä»–æ–‡æœ¬ï¼‰ï¼š
{{
  "complexity": "simple|moderate|complex|expert",
  "confidence": 0.0-1.0,
  "reasoning": "åˆ¤æ–­ç†ç”±"
}}
"""

    def __init__(
        self,
        llm_call_fn: Any | None = None,
        fallback_router: RuleBasedRouter | None = None,
        classifier_model: str = "gpt-4o-mini",
        enable_cache: bool = True,
    ) -> None:
        """
        åˆå§‹åŒ– LLM è·¯ç”±å™¨ã€‚

        å‚æ•°:
            llm_call_fn: LLM è°ƒç”¨å‡½æ•°ï¼ˆæ¥æ”¶ prompt: strï¼Œè¿”å› response: strï¼‰
            fallback_router: é™çº§è·¯ç”±å™¨ï¼ˆLLM è°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
            classifier_model: åˆ†ç±»å™¨ä½¿ç”¨çš„æ¨¡å‹ ID
            enable_cache: æ˜¯å¦å¯ç”¨åˆ†ç±»ç»“æœç¼“å­˜ï¼ˆé¿å…é‡å¤è°ƒç”¨ï¼‰
        """
        self.llm_call_fn = llm_call_fn
        self.fallback_router = fallback_router or RuleBasedRouter()
        self.classifier_model = classifier_model
        self.enable_cache = enable_cache

        # ç®€å•çš„å†…å­˜ç¼“å­˜ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨ Redis ç­‰æŒä¹…åŒ–ç¼“å­˜ï¼‰
        self._cache: dict[str, dict[str, Any]] = {}

        # å¤æ‚åº¦ä¼°è®¡å™¨ï¼ˆç”¨äº fallbackï¼‰
        self.complexity_estimator = ComplexityEstimator()

    def route(self, context: RoutingContext) -> RoutingDecision:
        """
        æ‰§è¡Œè·¯ç”±å†³ç­–ã€‚

        å‚æ•°:
            context: è·¯ç”±ä¸Šä¸‹æ–‡

        è¿”å›:
            è·¯ç”±å†³ç­–ç»“æœ
        """
        # 1. æ£€æŸ¥ç¼“å­˜
        if self.enable_cache and context.query in self._cache:
            cached = self._cache[context.query]
            return self._route_by_classification(
                context,
                complexity=cached["complexity"],
                confidence=cached["confidence"],
                reasoning=cached["reasoning"],
            )

        # 2. å°è¯• LLM åˆ†ç±»
        if self.llm_call_fn is not None:
            try:
                classification = self._classify_with_llm(context.query)
                if classification:
                    # ç¼“å­˜ç»“æœ
                    if self.enable_cache:
                        self._cache[context.query] = classification

                    return self._route_by_classification(
                        context,
                        complexity=classification["complexity"],
                        confidence=classification["confidence"],
                        reasoning=classification["reasoning"],
                    )
            except Exception as e:
                # LLM è°ƒç”¨å¤±è´¥ï¼Œè®°å½•è­¦å‘Šå¹¶é™çº§
                warnings.warn(
                    f"LLM è·¯ç”±å¤±è´¥ï¼Œé™çº§åˆ°è§„åˆ™è·¯ç”±å™¨: {e}",
                    category=RuntimeWarning,
                    stacklevel=2,
                )

        # 3. Fallback åˆ°è§„åˆ™è·¯ç”±å™¨
        return self.fallback_router.route(context)

    def _classify_with_llm(self, query: str) -> dict[str, Any] | None:
        """
        ä½¿ç”¨ LLM å¯¹æŸ¥è¯¢è¿›è¡Œåˆ†ç±»ã€‚

        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬

        è¿”å›:
            åˆ†ç±»ç»“æœå­—å…¸ï¼ˆcomplexity, confidence, reasoningï¼‰ï¼Œå¤±è´¥æ—¶è¿”å› None
        """
        if self.llm_call_fn is None:
            return None

        # æ„å»º Prompt
        prompt = self.CLASSIFICATION_PROMPT_TEMPLATE.format(query=query)

        try:
            # è°ƒç”¨ LLM
            # ğŸ­ ç”Ÿäº§æç¤ºï¼šè¿™é‡Œéœ€è¦å¤„ç†è¶…æ—¶ã€é‡è¯•ã€é€Ÿç‡é™åˆ¶ç­‰
            response = self.llm_call_fn(prompt)

            # è§£æ JSON å“åº”
            import json

            # å»é™¤å¯èƒ½çš„ Markdown ä»£ç å—åŒ…è£¹
            response = response.strip()
            if response.startswith("```"):
                lines = response.split("\n")
                response = "\n".join(lines[1:-1])
            if response.startswith("json"):
                response = response[4:].strip()

            data = json.loads(response)

            # æ ¡éªŒå­—æ®µ
            complexity_str = data.get("complexity", "moderate").lower()
            confidence = float(data.get("confidence", 0.5))
            reasoning = data.get("reasoning", "")

            # æ˜ å°„åˆ° ComplexityLevel
            complexity_map = {
                "simple": ComplexityLevel.SIMPLE,
                "moderate": ComplexityLevel.MODERATE,
                "complex": ComplexityLevel.COMPLEX,
                "expert": ComplexityLevel.EXPERT,
            }
            complexity = complexity_map.get(complexity_str, ComplexityLevel.MODERATE)

            return {
                "complexity": complexity,
                "confidence": confidence,
                "reasoning": reasoning,
            }

        except Exception as e:
            # è§£æå¤±è´¥æˆ– LLM è°ƒç”¨å¤±è´¥
            raise RoutingError(
                what="LLM åˆ†ç±»å¤±è´¥",
                why=f"æ— æ³•è§£æ LLM å“åº”æˆ–è°ƒç”¨å¤±è´¥: {e}",
                how="è¯·æ£€æŸ¥ LLM Provider æ˜¯å¦æ­£å¸¸ï¼Œæˆ–ä½¿ç”¨ fallback_router",
            ) from e

    def _route_by_classification(
        self,
        context: RoutingContext,
        complexity: ComplexityLevel,
        confidence: float,
        reasoning: str,
    ) -> RoutingDecision:
        """
        æ ¹æ®åˆ†ç±»ç»“æœè¿›è¡Œè·¯ç”±ã€‚

        å‚æ•°:
            context: è·¯ç”±ä¸Šä¸‹æ–‡
            complexity: åˆ†ç±»å¾—å‡ºçš„å¤æ‚åº¦
            confidence: åˆ†ç±»ç½®ä¿¡åº¦
            reasoning: åˆ†ç±»æ¨ç†

        è¿”å›:
            è·¯ç”±å†³ç­–
        """
        # [Design Decision] ä½¿ç”¨ fallback_router çš„è§„åˆ™å¼•æ“æ¥å®é™…æ‰§è¡Œè·¯ç”±ï¼Œ
        # LLM åªè´Ÿè´£å¤æ‚åº¦åˆ†ç±»ã€‚è¿™æ ·å¯ä»¥å¤ç”¨è§„åˆ™é…ç½®ï¼Œé¿å…é‡å¤å®šä¹‰æ˜ å°„é€»è¾‘ã€‚

        # ä¸´æ—¶ä¿®æ”¹ context çš„å¤æ‚åº¦ï¼ˆé€šè¿‡åœ¨ metadata ä¸­ä¼ é€’ï¼‰
        modified_context = RoutingContext(
            segments=context.segments,
            query=context.query,
            max_budget_tokens=context.max_budget_tokens,
            current_turn=context.current_turn,
            metadata={
                **(context.metadata or {}),
                "_llm_complexity": complexity,
                "_llm_confidence": confidence,
            },
        )

        # ä½¿ç”¨ fallback_router çš„è§„åˆ™å¼•æ“è¿›è¡Œè·¯ç”±
        decision = self.fallback_router.route(modified_context)

        # æ›´æ–°å†³ç­–ä¿¡æ¯ï¼Œæ ‡æ³¨ä¸º LLM è·¯ç”±
        return RoutingDecision(
            selected_model=decision.selected_model,
            complexity=complexity,
            matched_rule=f"llm_classified:{decision.matched_rule}",
            is_fallback=decision.is_fallback,
            confidence=confidence,
            reasoning=f"LLM åˆ†ç±»: {reasoning} | {decision.reasoning}",
            estimated_cost=decision.estimated_cost,
        )


def create_mock_llm_call_fn() -> Any:
    """
    åˆ›å»º Mock LLM è°ƒç”¨å‡½æ•°ï¼ˆç”¨äºæµ‹è¯•å’Œç¤ºä¾‹ï¼‰ã€‚

    â†’ ä»…ä¾›å¼€å‘æµ‹è¯•ä½¿ç”¨

    è¿”å›:
        Mock å‡½æ•°ï¼Œæ ¹æ®æŸ¥è¯¢é•¿åº¦è¿”å›å›ºå®šçš„åˆ†ç±»ç»“æœ
    """

    def mock_llm_call(prompt: str) -> str:
        """Mock LLM è°ƒç”¨ â€” æ ¹æ®æŸ¥è¯¢é•¿åº¦ç®€å•åˆ†ç±»ã€‚"""
        # ä» prompt ä¸­æå–æŸ¥è¯¢ï¼ˆç®€å•å­—ç¬¦ä¸²åŒ¹é…ï¼‰
        lines = prompt.split("\n")
        query = ""
        for i, line in enumerate(lines):
            if "ç”¨æˆ·æŸ¥è¯¢ï¼š" in line and i + 1 < len(lines):
                query = lines[i + 1]
                break

        # ç®€å•çš„é•¿åº¦åˆ†ç±»
        query_len = len(query)
        if query_len < 50:
            complexity = "simple"
            confidence = 0.85
            reasoning = "æŸ¥è¯¢ç®€çŸ­ï¼Œå¯èƒ½æ˜¯ç®€å•é—®é¢˜"
        elif query_len < 150:
            complexity = "moderate"
            confidence = 0.75
            reasoning = "æŸ¥è¯¢ä¸­ç­‰é•¿åº¦ï¼Œéœ€è¦ä¸€å®šåˆ†æ"
        elif query_len < 400:
            complexity = "complex"
            confidence = 0.80
            reasoning = "æŸ¥è¯¢è¾ƒé•¿ï¼Œå¯èƒ½éœ€è¦æ·±åº¦æ¨ç†"
        else:
            complexity = "expert"
            confidence = 0.90
            reasoning = "æŸ¥è¯¢éå¸¸é•¿ï¼Œå¯èƒ½æ˜¯ä¸“å®¶çº§é—®é¢˜"

        import json

        return json.dumps(
            {
                "complexity": complexity,
                "confidence": confidence,
                "reasoning": reasoning,
            },
            ensure_ascii=False,
        )

    return mock_llm_call
