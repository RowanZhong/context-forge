"""
ContextForge â€” é¡¶å±‚ Facade APIã€‚

è¿™æ˜¯ Context Forge çš„ä¸»å…¥å£ï¼Œé¢å‘ 80% çš„ç”¨æˆ·ã€‚
è®¾è®¡ç›®æ ‡ï¼š**3 è¡Œä»£ç å®Œæˆæ ¸å¿ƒåœºæ™¯ã€‚**

â†’ 6.1.2 Context Builder
â†’ æ¸è¿›å¼ API è®¾è®¡çš„ç¬¬ä¸€å±‚ï¼šHigh-Level Facade

ä½¿ç”¨ç¤ºä¾‹
--------

æœ€ç®€ç”¨æ³•ï¼ˆ3 è¡Œä»£ç ï¼‰::

    from context_forge import ContextForge

    forge = ContextForge(model="gpt-4o")
    context = await forge.build(
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚",
        messages=[{"role": "user", "content": "ä½ å¥½"}],
    )
    # context.to_messages() â†’ ç›´æŽ¥ä¼ ç»™ LLM API

å¸¦ RAG ç‰‡æ®µ::

    context = await forge.build(
        system_prompt="ä½ æ˜¯ä¸€ä¸ªå®¢æœåŠ©æ‰‹ã€‚",
        messages=conversation_history,
        rag_chunks=[
            {"content": "é€€è´§æ”¿ç­–ï¼š7å¤©å†…å¯é€€...", "score": 0.95},
            {"content": "é€€æ¬¾æµç¨‹ï¼šæäº¤ç”³è¯·åŽ...", "score": 0.87},
        ],
    )

åŒæ­¥ç”¨æ³•::

    context = forge.build_sync(
        system_prompt="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚",
        messages=[{"role": "user", "content": "ä½ å¥½"}],
    )

# [DX Decision] Facade æ˜¯æ•´ä¸ªå¼•æ“Žçš„"å‰é—¨"ã€‚
# å®ƒçš„è®¾è®¡éµå¾ªä»¥ä¸‹åŽŸåˆ™ï¼š
# 1. æœ€å°‘å‚æ•°å®Œæˆæœ€å¸¸è§ä»»åŠ¡ï¼ˆsystem_prompt + messages å³å¯ï¼‰
# 2. æ‰€æœ‰é«˜çº§åŠŸèƒ½é€šè¿‡å¯é€‰å‚æ•°æš´éœ²ï¼ˆæ¸è¿›å¼æš´éœ²ï¼‰
# 3. åˆç†é»˜è®¤å€¼è¦†ç›– 80% åœºæ™¯ï¼ˆé›¶é…ç½®å¯åŠ¨ï¼‰
# 4. é”™è¯¯ä¿¡æ¯å‘Šè¯‰ç”¨æˆ·æ€Žä¹ˆä¿®ï¼Œè€Œéžåªè¯´ä»€ä¹ˆåäº†
"""

from __future__ import annotations

import asyncio
import logging
import time
from pathlib import Path
from typing import Any

from context_forge.config.defaults import resolve_model
from context_forge.config.loader import load_policy
from context_forge.config.schema import PolicyConfig
from context_forge.facade_observability import ObservabilityMixin
from context_forge.models.budget import BudgetAllocation, BudgetPolicy
from context_forge.models.context_package import ContextPackage
from context_forge.models.control import ControlFlags
from context_forge.models.metadata import SegmentMetadata
from context_forge.models.provenance import Provenance, SourceType
from context_forge.models.routing import RoutingDecision
from context_forge.models.segment import Priority, Segment, SegmentType
from context_forge.pipeline.base import Pipeline, PipelineContext, create_default_pipeline
from context_forge.tokenizer.registry import get_tokenizer

logger = logging.getLogger(__name__)


class ContextForge(ObservabilityMixin):
    """
    Context Forge é¡¶å±‚å…¥å£ â€” 3 è¡Œä»£ç å®Œæˆä¸Šä¸‹æ–‡ç»„è£…ã€‚

    è¿™æ˜¯é¢å‘ 80% ç”¨æˆ·çš„ High-Level APIã€‚å®ƒå°è£…äº†å®Œæ•´çš„æµæ°´çº¿ã€
    é¢„ç®—ç®¡ç†ã€æ¸…æ´—å’Œç¼“å­˜é€»è¾‘ï¼Œç”¨æˆ·åªéœ€è¦å…³å¿ƒè¾“å…¥å’Œè¾“å‡ºã€‚

    æ¸è¿›å¼ API å±‚çº§ï¼š
    - **ç¬¬ä¸€å±‚**ï¼ˆæœ¬ç±»ï¼‰ï¼šæœ€å°‘å‚æ•°ï¼Œæœ€å¿«ä¸Šæ‰‹
    - **ç¬¬äºŒå±‚**ï¼ˆPipeline + PipelineContextï¼‰ï¼šç²¾ç»†æŽ§åˆ¶å„é˜¶æ®µ
    - **ç¬¬ä¸‰å±‚**ï¼ˆPlugin Protocolsï¼‰ï¼šè‡ªå®šä¹‰ç»„ä»¶

    åŸºæœ¬åˆå§‹åŒ–::

        forge = ContextForge(model="gpt-4o")

    å¸¦ç­–ç•¥æ–‡ä»¶::

        forge = ContextForge(
            model="claude-sonnet-4-5-20250514",
            policy_path="configs/production.yaml",
        )

    è‡ªå®šä¹‰é…ç½®::

        forge = ContextForge(
            model="gpt-4o",
            max_context_tokens=32768,
            output_reserved_tokens=2048,
        )

    å‚æ•°:
        model: ç›®æ ‡æ¨¡åž‹åç§°æˆ–åˆ«åã€‚æ”¯æŒç®€å†™å¦‚ "gpt-4o"ã€"sonnet"ã€"haiku"ã€‚
        policy_path: YAML ç­–ç•¥æ–‡ä»¶è·¯å¾„ã€‚None æ—¶ä½¿ç”¨é»˜è®¤é…ç½®ã€‚
        max_context_tokens: è¦†ç›–ç­–ç•¥ä¸­çš„æœ€å¤§ä¸Šä¸‹æ–‡ Token æ•°ã€‚
        output_reserved_tokens: è¦†ç›–ç­–ç•¥ä¸­çš„ Output é¢„ç•™ã€‚
        thinking_reserved_tokens: è¦†ç›–ç­–ç•¥ä¸­çš„ Thinking Token é¢„ç•™ã€‚
        debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆè¯¦ç»†æ—¥å¿—è¾“å‡ºï¼‰ã€‚
        pipeline: è‡ªå®šä¹‰ Pipeline å®žä¾‹ï¼ˆé«˜çº§ç”¨æ³•ï¼‰ã€‚
        cache_backend: è‡ªå®šä¹‰ç¼“å­˜åŽç«¯ï¼ˆé«˜çº§ç”¨æ³•ï¼‰ã€‚
        router: è‡ªå®šä¹‰è·¯ç”±å™¨ï¼ˆé«˜çº§ç”¨æ³•ï¼‰ã€‚
        metrics_collector: è‡ªå®šä¹‰æŒ‡æ ‡æ”¶é›†å™¨ï¼ˆé«˜çº§ç”¨æ³•ï¼‰ã€‚
        snapshot_manager: è‡ªå®šä¹‰å¿«ç…§ç®¡ç†å™¨ï¼ˆé«˜çº§ç”¨æ³•ï¼‰ã€‚
    """

    def __init__(
        self,
        model: str = "gpt-4o",
        policy_path: str | Path | None = None,
        max_context_tokens: int | None = None,
        output_reserved_tokens: int | None = None,
        thinking_reserved_tokens: int | None = None,
        debug: bool = False,
        pipeline: Pipeline | None = None,
        cache_backend: Any | None = None,
        router: Any | None = None,
        metrics_collector: Any | None = None,
        snapshot_manager: Any | None = None,
    ) -> None:
        # è§£æžæ¨¡åž‹é…ç½®
        # [DX Decision] æ ¹æ®æ¨¡åž‹åè‡ªåŠ¨ç¡®å®šçª—å£å¤§å°å’Œ tokenizerï¼Œ
        # ç”¨æˆ·ä¸éœ€è¦æŸ¥é˜…å„åŽ‚å•†æ–‡æ¡£æ¥èŽ·å–è¿™äº›ä¿¡æ¯ã€‚
        self._model_config = resolve_model(model)
        self._model = self._model_config.model_id
        self._debug = debug

        # åŠ è½½ç­–ç•¥
        self._policy = load_policy(path=policy_path)

        # åº”ç”¨è¿è¡Œæ—¶è¦†ç›–
        overrides: dict[str, Any] = {}
        if max_context_tokens is not None:
            overrides["max_context_tokens"] = max_context_tokens
        elif self._model_config:
            overrides["max_context_tokens"] = self._model_config.max_context_tokens

        if output_reserved_tokens is not None:
            overrides["output_reserved_tokens"] = output_reserved_tokens
        if thinking_reserved_tokens is not None:
            overrides["thinking_reserved_tokens"] = thinking_reserved_tokens
        elif self._model_config.supports_thinking:
            # è‡ªåŠ¨ä¸º Reasoning Model é¢„ç•™ Thinking Token
            overrides["thinking_reserved_tokens"] = 8192

        if overrides:
            budget_dict = self._policy.budget.model_dump()
            budget_dict.update(overrides)
            from context_forge.config.schema import BudgetConfig
            self._policy = self._policy.model_copy(update={
                "budget": BudgetConfig(**budget_dict)
            })

        # åˆ›å»ºé¢„ç®—ç­–ç•¥
        self._budget_policy = self._policy.to_budget_policy()

        # åˆ›å»ºæˆ–ä½¿ç”¨è‡ªå®šä¹‰ Pipeline
        # [DX Decision] ä¼ é€’ policy é…ç½®ç»™ pipelineï¼Œè®©å„é˜¶æ®µæ ¹æ®é…ç½®è‡ªåŠ¨è°ƒæ•´
        self._pipeline = pipeline or create_default_pipeline(policy=self._policy)

        # Tokenizer
        self._tokenizer = get_tokenizer(self._model)

        # ç¬¬ä¸‰è½®ï¼šç¼“å­˜ã€è·¯ç”±ã€å¯è§‚æµ‹æ€§
        # [DX Decision] å»¶è¿Ÿåˆå§‹åŒ–ï¼Œä»…åœ¨å¯ç”¨æ—¶æ‰åˆ›å»ºå¯¹è±¡
        self._cache_manager: Any = None
        self._router: Any = None
        self._metrics_collector: Any = None
        self._snapshot_manager: Any = None

        # æ ¹æ® policy é…ç½®åˆå§‹åŒ–å¯é€‰ç»„ä»¶
        if self._policy.cache.enabled:
            if cache_backend is None:
                from context_forge.cache import CacheManager, MemoryCache

                l1_cache = MemoryCache(
                    max_size=self._policy.cache.max_entries,
                    default_ttl=self._policy.cache.ttl_seconds,
                )
                self._cache_manager = CacheManager(l1=l1_cache)
            else:
                self._cache_manager = cache_backend

        if self._policy.routing.enabled:
            if router is None:
                from context_forge.models.routing import RoutingRule
                from context_forge.routing import RuleBasedRouter

                # å°†é…ç½®ä¸­çš„è§„åˆ™å­—å…¸è½¬æ¢ä¸º RoutingRule å¯¹è±¡
                rules = [
                    RoutingRule(**rule_dict) if isinstance(rule_dict, dict) else rule_dict
                    for rule_dict in (self._policy.routing.rules or [])
                ]

                self._router = RuleBasedRouter(
                    default_model=self._policy.routing.default_model,
                    rules=rules,
                )
            else:
                self._router = router

        if self._policy.observability.metrics_enabled:
            if metrics_collector is None:
                from context_forge.observability import MetricsCollector

                self._metrics_collector = MetricsCollector()
            else:
                self._metrics_collector = metrics_collector

        if self._policy.observability.snapshot_enabled:
            if snapshot_manager is None:
                from context_forge.observability import SnapshotManager

                self._snapshot_manager = SnapshotManager(
                    storage_dir=self._policy.observability.snapshot_dir
                )
            else:
                self._snapshot_manager = snapshot_manager

        if self._debug:
            logging.basicConfig(level=logging.DEBUG)
            logger.debug(
                "ContextForge åˆå§‹åŒ–å®Œæˆï¼šmodel=%s, "
                "max_tokens=%d, output_reserved=%d, thinking_reserved=%d, "
                "cache=%s, routing=%s, observability=%s",
                self._model,
                self._budget_policy.max_context_tokens,
                self._budget_policy.output_reserved_tokens,
                self._budget_policy.thinking_reserved_tokens,
                "enabled" if self._cache_manager else "disabled",
                "enabled" if self._router else "disabled",
                "enabled" if self._snapshot_manager else "disabled",
            )

    async def build(
        self,
        system_prompt: str = "",
        messages: list[dict[str, str]] | None = None,
        rag_chunks: list[dict[str, Any]] | None = None,
        tools: list[dict[str, Any]] | None = None,
        few_shot_examples: list[dict[str, str]] | None = None,
        state: dict[str, Any] | None = None,
        extra_segments: list[Segment] | None = None,
        current_turn: int = 0,
        namespace: str = "default",
        check_antipatterns: bool = False,
    ) -> ContextPackage:
        """
        ç»„è£…ä¸Šä¸‹æ–‡ â€” å¼‚æ­¥ä¸» APIã€‚

        è¿™æ˜¯æœ€å¸¸ç”¨çš„æ–¹æ³•ã€‚ä¼ å…¥åŽŸå§‹è¾“å…¥ï¼Œè¿”å›žç»„è£…å¥½çš„ ContextPackageã€‚

        å‚æ•°:
            system_prompt: ç³»ç»Ÿæç¤ºæ–‡æœ¬
            messages: å¯¹è¯åŽ†å²æ¶ˆæ¯åˆ—è¡¨ [{"role": "user/assistant", "content": "..."}]
            rag_chunks: RAG æ£€ç´¢ç‰‡æ®µ [{"content": "...", "score": 0.9, ...}]
            tools: å·¥å…·å®šä¹‰åˆ—è¡¨ [{"name": "...", "description": "...", ...}]
            few_shot_examples: å°‘æ ·æœ¬ç¤ºä¾‹ [{"role": "user/assistant", "content": "..."}]
            state: çŠ¶æ€é”šç‚¹ {"key": "value", ...}
            extra_segments: é¢„æž„å»ºçš„ Segment åˆ—è¡¨ï¼ˆé«˜çº§ç”¨æ³•ï¼‰
            current_turn: å½“å‰å¯¹è¯è½®æ¬¡
            namespace: ç›®æ ‡å‘½åç©ºé—´
            check_antipatterns: æ˜¯å¦åœ¨æž„å»ºåŽè‡ªåŠ¨æ£€æµ‹åæ¨¡å¼ï¼ˆâ†’ 6.7ï¼‰

        è¿”å›ž:
            ContextPackage â€” ç»„è£…ç»“æžœï¼Œè°ƒç”¨ .to_messages() èŽ·å– LLM API æ ¼å¼

        å¼‚å¸¸:
            BudgetExceededError: å†…å®¹è¶…å‡ºé¢„ç®—ä¸”æ— æ³•é™çº§
            SanitizationError: æ¸…æ´—è¿‡ç¨‹ä¸­å‘çŽ°ä¸å¯ä¿®å¤çš„é—®é¢˜
        """
        start_time = time.perf_counter()

        # ç¬¬ä¸€æ­¥ï¼šå°†å„ç§è¾“å…¥è½¬æ¢ä¸º Segment åˆ—è¡¨
        # [DX Decision] æå‰è½¬æ¢ï¼Œç”¨äºŽè·¯ç”±å†³ç­–å’Œç¼“å­˜è®¡ç®—
        segments = self._prepare_segments(
            system_prompt=system_prompt,
            messages=messages or [],
            rag_chunks=rag_chunks or [],
            tools=tools or [],
            few_shot_examples=few_shot_examples or [],
            state=state,
            extra_segments=extra_segments or [],
            current_turn=current_turn,
        )

        # ç¬¬äºŒæ­¥ï¼šè·¯ç”±å†³ç­–ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        routing_decision: RoutingDecision | None = None
        target_model = self._model
        adjusted_budget_policy = self._budget_policy

        if self._router:
            # æž„å»ºè·¯ç”±ä¸Šä¸‹æ–‡
            # â†’ 6.6.1 æ„å›¾é©±åŠ¨è·¯ç”±
            from context_forge.routing.base import RoutingContext

            # æž„å»ºæŸ¥è¯¢æ–‡æœ¬ï¼ˆç”¨äºŽå…³é”®è¯åŒ¹é…å’Œå¤æ‚åº¦åˆ†æžï¼‰
            query_parts = []
            if system_prompt:
                query_parts.append(system_prompt)
            if messages:
                # ä½¿ç”¨æœ€åŽä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä½œä¸ºå½“å‰æŸ¥è¯¢
                for msg in reversed(messages):
                    if msg.get("role") == "user":
                        query_parts.append(msg.get("content", ""))
                        break
            query = " ".join(query_parts)

            routing_context = RoutingContext(
                segments=segments,
                query=query,
                max_budget_tokens=self._budget_policy.max_context_tokens,
                current_turn=current_turn,
                metadata={"namespace": namespace},
            )

            # æ‰§è¡Œè·¯ç”±å†³ç­–ï¼ˆåŒæ­¥æ–¹æ³•ï¼‰
            routing_decision = self._router.route(routing_context)
            assert routing_decision is not None  # ç±»åž‹å®ˆå«
            target_model = routing_decision.selected_model.model_id
            # [DX Decision] RoutingDecision æš‚ä¸æ”¯æŒ budget_adjustmentï¼Œ
            # å¯åœ¨åŽç»­ç‰ˆæœ¬æ‰©å±•ä»¥æ”¯æŒåŠ¨æ€é¢„ç®—è°ƒæ•´
            if hasattr(routing_decision, 'budget_adjustment') and routing_decision.budget_adjustment:
                adjusted_budget_policy = self._budget_policy.model_copy(
                    update=routing_decision.budget_adjustment
                )

        # ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥ç¼“å­˜ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        cache_key = None
        if self._cache_manager:
            # æž„å»ºç¼“å­˜é”®ï¼ˆåŸºäºŽè¾“å…¥å’Œæ¨¡åž‹ï¼‰
            import hashlib
            import json

            cache_input = {
                "model": target_model,
                "system_prompt": system_prompt,
                "messages": messages,
                "rag_chunks": rag_chunks,
                "tools": tools,
                "few_shot_examples": few_shot_examples,
                "state": state,
                "namespace": namespace,
            }
            cache_key = hashlib.sha256(
                json.dumps(cache_input, sort_keys=True).encode()
            ).hexdigest()

            cached_entry = await self._cache_manager.get(cache_key)
            if cached_entry:
                if self._debug:
                    logger.debug(f"ç¼“å­˜å‘½ä¸­ï¼š{cache_key[:16]}...")
                # è®°å½•ç¼“å­˜å‘½ä¸­æŒ‡æ ‡
                if self._metrics_collector:
                    self._metrics_collector.record("cache_hit", 1.0, tags={"model": target_model})
                # ååºåˆ—åŒ– ContextPackage
                cached_dict = json.loads(cached_entry.value)
                # ç®€åŒ–ï¼šç›´æŽ¥è¿”å›žé‡æ–°æž„å»ºçš„ package
                # ðŸ­ ç”Ÿäº§æç¤ºï¼šåº”è¯¥å®žçŽ° ContextPackage.from_dict() æ–¹æ³•
                # è¿™é‡Œä¸ºäº†å‘åŽå…¼å®¹ï¼Œæš‚æ—¶è·³è¿‡ç¼“å­˜ï¼ˆåœ¨æµ‹è¯•ä¸­ç¦ç”¨ï¼‰
                if self._debug:
                    logger.debug("ç¼“å­˜å‘½ä¸­ï¼Œä½†ååºåˆ—åŒ–æš‚æœªå®žçŽ°ï¼Œç»§ç»­æž„å»º")

        # ç¬¬å››æ­¥ï¼šåˆ›å»º Pipeline ä¸Šä¸‹æ–‡
        pipeline_context = PipelineContext(
            model=target_model,
            budget_policy=adjusted_budget_policy,
            current_turn=current_turn,
            target_namespace=namespace,
            debug=self._debug,
        )

        # ä¼ é€’é¢„ç®—ä¿¡æ¯ç»™ CompressStage
        pipeline_context.metadata["available_tokens"] = adjusted_budget_policy.available_for_content
        pipeline_context.metadata["model_name"] = target_model

        # ç¬¬äº”æ­¥ï¼šæ‰§è¡Œæµæ°´çº¿
        result_segments = await self._pipeline.execute(segments, pipeline_context)

        # ç¬¬å…­æ­¥ï¼šç»„è£… ContextPackage
        elapsed_ms = (time.perf_counter() - start_time) * 1000

        budget_allocation = pipeline_context.metadata.get("budget_allocation")
        if not isinstance(budget_allocation, BudgetAllocation):
            # å¦‚æžœ Allocate é˜¶æ®µæ²¡æœ‰ç”Ÿæˆåˆ†é…è®°å½•ï¼Œåˆ›å»ºä¸€ä¸ªåŸºç¡€çš„
            total_tokens = sum(s.token_count or 0 for s in result_segments)
            budget_allocation = BudgetAllocation(
                total_budget=adjusted_budget_policy.max_context_tokens,
                content_budget=adjusted_budget_policy.available_for_content,
                total_used=total_tokens,
            )

        package = ContextPackage(
            segments=result_segments,
            audit_log=pipeline_context.audit_log,
            budget_allocation=budget_allocation,
            routing_decision=routing_decision,
            model=target_model,
            policy_version=self._policy.version,
            assembly_duration_ms=elapsed_ms,
            warnings=pipeline_context.warnings,
        )

        # ç¬¬ä¸ƒæ­¥ï¼šä¿å­˜åˆ°ç¼“å­˜ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        if self._cache_manager and cache_key:
            import json

            from context_forge.cache.base import CacheEntry

            # åºåˆ—åŒ– ContextPackage
            package_dict = package.to_snapshot_dict()
            # ä½¿ç”¨ default=str å¤„ç†æ—¥æœŸæ—¶é—´ç­‰æ— æ³•åºåˆ—åŒ–çš„å¯¹è±¡
            cache_entry = CacheEntry(
                value=json.dumps(package_dict, ensure_ascii=False, default=str)
            )
            await self._cache_manager.set(cache_key, cache_entry)
            if self._debug:
                logger.debug(f"ç¼“å­˜ä¿å­˜ï¼š{cache_key[:16]}...")

        # ç¬¬å…«æ­¥ï¼šä¿å­˜å¿«ç…§ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        if self._snapshot_manager:
            snapshot_id = await self._snapshot_manager.save(package)
            if self._debug:
                logger.debug(f"å¿«ç…§å·²ä¿å­˜ï¼š{snapshot_id}")

        # ç¬¬ä¹æ­¥ï¼šè®°å½•æŒ‡æ ‡ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        if self._metrics_collector:
            self._metrics_collector.collect_from_package(package)

        # ç¬¬åæ­¥ï¼šåæ¨¡å¼æ£€æµ‹ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        # â†’ 6.7 åæ¨¡å¼æ£€æµ‹ä¸Žè¯Šæ–­
        if check_antipatterns or self._policy.antipattern.check_on_build:
            antipattern_results = self.detect_antipatterns(package, format="raw")
            if antipattern_results and isinstance(antipattern_results, list):
                import warnings

                from context_forge.antipattern.base import AntiPatternSeverity

                # ç»Ÿè®¡å„çº§åˆ«é—®é¢˜æ•°é‡
                critical_count = len([r for r in antipattern_results if r.severity == AntiPatternSeverity.CRITICAL])
                warning_count = len([r for r in antipattern_results if r.severity == AntiPatternSeverity.WARNING])

                # å‘å‡ºè­¦å‘Š
                warnings.warn(
                    f"æ£€æµ‹åˆ° {len(antipattern_results)} ä¸ªåæ¨¡å¼é—®é¢˜ "
                    f"(CRITICAL: {critical_count}, WARNING: {warning_count})ã€‚"
                    f"è°ƒç”¨ detect_antipatterns() æŸ¥çœ‹è¯¦æƒ…ã€‚",
                    UserWarning,
                    stacklevel=2,
                )

                # å¦‚æžœé…ç½®è¦æ±‚ï¼Œåœ¨æ£€æµ‹åˆ° CRITICAL æ—¶æŠ›å¼‚å¸¸
                if self._policy.antipattern.fail_on_critical and critical_count > 0:
                    from context_forge.errors.exceptions import AntiPatternError
                    raise AntiPatternError(
                        f"æ£€æµ‹åˆ° {critical_count} ä¸ª CRITICAL çº§åˆ«çš„åæ¨¡å¼é—®é¢˜ã€‚\n"
                        f"è°ƒç”¨ detect_antipatterns() æŸ¥çœ‹è¯¦æƒ…ã€‚"
                    )

        if self._debug:
            logger.debug("ç»„è£…å®Œæˆï¼š%s", package.summary())

        return package

    def build_sync(
        self,
        system_prompt: str = "",
        messages: list[dict[str, str]] | None = None,
        rag_chunks: list[dict[str, Any]] | None = None,
        tools: list[dict[str, Any]] | None = None,
        few_shot_examples: list[dict[str, str]] | None = None,
        state: dict[str, Any] | None = None,
        extra_segments: list[Segment] | None = None,
        current_turn: int = 0,
        namespace: str = "default",
        check_antipatterns: bool = False,
    ) -> ContextPackage:
        """
        ç»„è£…ä¸Šä¸‹æ–‡ â€” åŒæ­¥ä¾¿æ·æ–¹æ³•ã€‚

        # [DX Decision] ä¸ºä¸ä½¿ç”¨ async çš„ç”¨æˆ·æä¾›åŒæ­¥åŒ…è£…ã€‚
        # åœ¨ Jupyter Notebook æˆ–ç®€å•è„šæœ¬ä¸­ç‰¹åˆ«æœ‰ç”¨ã€‚
        # å†…éƒ¨ä½¿ç”¨ asyncio.run()ï¼Œå¦‚æžœå·²åœ¨ event loop ä¸­è¿è¡Œ
        # ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ç»™å‡ºå‹å¥½æç¤ºã€‚

        å‚æ•°å’Œè¿”å›žå€¼ä¸Ž build() ç›¸åŒã€‚
        """
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = None

        if loop is not None:
            # å·²åœ¨ event loop ä¸­ï¼ˆå¦‚ Jupyterï¼‰ï¼Œæä¾›å‹å¥½æç¤º
            import warnings
            warnings.warn(
                "æ£€æµ‹åˆ°å·²æœ‰è¿è¡Œä¸­çš„ event loopï¼ˆå¯èƒ½åœ¨ Jupyter çŽ¯å¢ƒä¸­ï¼‰ã€‚"
                "build_sync() æ— æ³•åœ¨å·²æœ‰ event loop ä¸­ä½¿ç”¨ã€‚"
                "è¯·ä½¿ç”¨ 'await forge.build(...)' ä»£æ›¿ï¼Œ"
                "æˆ–å®‰è£… nest_asyncioï¼špip install nest_asyncio",
                RuntimeWarning,
                stacklevel=2,
            )
            try:
                import nest_asyncio
                nest_asyncio.apply()
            except ImportError:
                raise RuntimeError(
                    "åœ¨å·²æœ‰ event loop ä¸­è°ƒç”¨ build_sync() éœ€è¦ nest_asyncioã€‚\n"
                    "â†’ ä¿®å¤æ–¹æ¡ˆ 1ï¼šä½¿ç”¨ 'await forge.build(...)' ä»£æ›¿\n"
                    "â†’ ä¿®å¤æ–¹æ¡ˆ 2ï¼špip install nest_asyncio"
                ) from None

        return asyncio.run(self.build(
            system_prompt=system_prompt,
            messages=messages,
            rag_chunks=rag_chunks,
            tools=tools,
            few_shot_examples=few_shot_examples,
            state=state,
            extra_segments=extra_segments,
            current_turn=current_turn,
            namespace=namespace,
            check_antipatterns=check_antipatterns,
        ))

    def _prepare_segments(
        self,
        system_prompt: str,
        messages: list[dict[str, str]],
        rag_chunks: list[dict[str, Any]],
        tools: list[dict[str, Any]],
        few_shot_examples: list[dict[str, str]],
        state: dict[str, Any] | None,
        extra_segments: list[Segment],
        current_turn: int,
    ) -> list[Segment]:
        """
        å°†å„ç§è¾“å…¥ç»Ÿä¸€è½¬æ¢ä¸º Segment åˆ—è¡¨ã€‚

        # [DX Decision] ç”¨æˆ·å¯ä»¥ä¼ å…¥ç®€å•çš„ dict æ ¼å¼ï¼Œ
        # Facade è´Ÿè´£å°†å®ƒä»¬åŒ…è£…ä¸ºç»“æž„åŒ–çš„ Segment å¯¹è±¡ã€‚
        # è¿™æ ·ç”¨æˆ·ä¸éœ€è¦äº†è§£ Segment æ¨¡åž‹çš„ç»†èŠ‚å°±èƒ½ä½¿ç”¨å¼•æ“Žã€‚
        """
        segments: list[Segment] = []

        # 1. System Prompt â†’ CRITICAL ä¼˜å…ˆçº§ï¼Œé”å®šä½ç½®
        if system_prompt:
            segments.append(Segment(
                type=SegmentType.SYSTEM,
                content=system_prompt,
                role="system",
                priority=Priority.CRITICAL,
                control=ControlFlags(
                    lock_position=True,
                    compressible=False,
                    must_keep=True,
                ),
                provenance=Provenance(
                    source_id="system_prompt",
                    source_type=SourceType.SYSTEM_CONFIG,
                ),
                metadata=SegmentMetadata(turn_number=0),
            ))

        # 2. Few-Shot ç¤ºä¾‹
        for i, example in enumerate(few_shot_examples):
            segments.append(Segment(
                type=SegmentType.FEW_SHOT,
                content=example.get("content", ""),
                role=example.get("role", "user"),
                priority=Priority.HIGH,
                control=ControlFlags(lock_position=True),
                provenance=Provenance(
                    source_id=f"few_shot_{i}",
                    source_type=SourceType.SYSTEM_CONFIG,
                ),
            ))

        # 3. å·¥å…·å®šä¹‰
        for i, tool in enumerate(tools):
            # å·¥å…·å®šä¹‰åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²
            import json
            tool_content = json.dumps(tool, ensure_ascii=False, indent=2)
            segments.append(Segment(
                type=SegmentType.TOOL_DEFINITION,
                content=tool_content,
                role="system",
                priority=Priority.HIGH,
                control=ControlFlags(namespace="tools"),
                provenance=Provenance(
                    source_id=f"tool_{tool.get('name', i)}",
                    source_type=SourceType.SYSTEM_CONFIG,
                ),
            ))

        # 4. å¯¹è¯åŽ†å²
        for i, msg in enumerate(messages):
            role = msg.get("role", "user")
            content = msg.get("content", "")
            msg_type = {
                "user": SegmentType.USER,
                "assistant": SegmentType.ASSISTANT,
                "system": SegmentType.SYSTEM,
            }.get(role, SegmentType.USER)

            segments.append(Segment(
                type=msg_type,
                content=content,
                role=role,
                provenance=Provenance(
                    source_id=f"message_{i}",
                    source_type=SourceType.USER_INPUT if role == "user" else SourceType.SYSTEM_CONFIG,
                ),
                metadata=SegmentMetadata(turn_number=i // 2),
            ))

        # 5. RAG æ£€ç´¢ç‰‡æ®µ
        for i, chunk in enumerate(rag_chunks):
            content = chunk.get("content", "") if isinstance(chunk, dict) else str(chunk)
            score = chunk.get("score", 0.0) if isinstance(chunk, dict) else 0.0
            source_id = chunk.get("source_id", f"rag_{i}") if isinstance(chunk, dict) else f"rag_{i}"
            uri = chunk.get("uri") if isinstance(chunk, dict) else None

            segments.append(Segment(
                type=SegmentType.RAG,
                content=content,
                role="user",  # RAG å†…å®¹é€šå¸¸ä½œä¸º user è§’è‰²æ³¨å…¥
                priority=Priority.MEDIUM,
                provenance=Provenance(
                    source_id=source_id,
                    source_type=SourceType.RAG_RETRIEVAL,
                    uri=uri,
                    retrieval_score=score,
                ),
                metadata=SegmentMetadata(
                    retrieval_score=score,
                    turn_number=current_turn,
                ),
            ))

        # 6. çŠ¶æ€é”šç‚¹ï¼ˆâ†’ 6.3.1.2 State Anchoringï¼‰
        if state:
            import json
            state_content = "å½“å‰çŠ¶æ€ï¼š\n" + json.dumps(state, ensure_ascii=False, indent=2)
            segments.append(Segment(
                type=SegmentType.STATE,
                content=state_content,
                role="system",
                priority=Priority.HIGH,
                control=ControlFlags(must_keep=True),
                provenance=Provenance(
                    source_id="state_anchor",
                    source_type=SourceType.SYSTEM_CONFIG,
                ),
            ))

        # 7. ç”¨æˆ·é¢„æž„å»ºçš„ Segmentï¼ˆé«˜çº§ç”¨æ³•ï¼‰
        segments.extend(extra_segments)

        return segments

    # --- ä¾¿æ·å±žæ€§ ---

    @property
    def model(self) -> str:
        """å½“å‰æ¨¡åž‹ IDã€‚"""
        return self._model

    @property
    def policy(self) -> PolicyConfig:
        """å½“å‰ç­–ç•¥é…ç½®ã€‚"""
        return self._policy

    @property
    def budget_policy(self) -> BudgetPolicy:
        """å½“å‰é¢„ç®—ç­–ç•¥ã€‚"""
        return self._budget_policy

    @property
    def pipeline(self) -> Pipeline:
        """å½“å‰æµæ°´çº¿å®žä¾‹ï¼ˆå¯ç”¨äºŽé«˜çº§å®šåˆ¶ï¼‰ã€‚"""
        return self._pipeline

    # --- åæ¨¡å¼æ£€æµ‹ä¾¿æ·æ–¹æ³•ï¼ˆç¬¬å››è½®æ–°å¢žï¼‰---

    def detect_antipatterns(
        self,
        package: ContextPackage,
        format: str = "text",
    ) -> list[Any] | str:
        """
        æ£€æµ‹ ContextPackage ä¸­çš„åæ¨¡å¼ã€‚

        â†’ 6.7 åæ¨¡å¼æ£€æµ‹ä¸Žè¯Šæ–­

        æ­¤æ–¹æ³•ä½¿ç”¨é»˜è®¤çš„åæ¨¡å¼æ£€æµ‹å™¨æ£€æŸ¥ä¸Šä¸‹æ–‡ç»„è£…ç»“æžœï¼Œ
        å‘çŽ°æ½œåœ¨çš„é…ç½®é—®é¢˜ã€å®‰å…¨é£Žé™©æˆ–æ€§èƒ½ç“¶é¢ˆã€‚

        å‚æ•°:
            package: è¦æ£€æµ‹çš„ ContextPackage
            format: è¾“å‡ºæ ¼å¼ï¼ˆ"text" / "json" / "rich" / "raw"ï¼‰
                   - "raw" è¿”å›ž DetectionResult åˆ—è¡¨
                   - å…¶ä»–æ ¼å¼è¿”å›žæ ¼å¼åŒ–çš„å­—ç¬¦ä¸²æŠ¥å‘Š

        è¿”å›ž:
            æ£€æµ‹ç»“æžœï¼ˆæ ¼å¼ç”± format å‚æ•°å†³å®šï¼‰

        ä½¿ç”¨ç¤ºä¾‹::

            # æ£€æµ‹å¹¶æ‰“å°æ–‡æœ¬æŠ¥å‘Š
            report = forge.detect_antipatterns(package, format="text")
            print(report)

            # èŽ·å–åŽŸå§‹ç»“æžœåˆ—è¡¨
            results = forge.detect_antipatterns(package, format="raw")
            for result in results:
                if result.severity == AntiPatternSeverity.CRITICAL:
                    print(f"ä¸¥é‡é—®é¢˜: {result.title}")
        """
        from context_forge.antipattern import create_default_detector
        from context_forge.antipattern.base import DetectionContext

        # åˆ›å»ºæ£€æµ‹å™¨
        detector = create_default_detector()

        # æž„å»ºæ£€æµ‹ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«ç­–ç•¥é…ç½®ä¸­çš„é˜ˆå€¼ï¼‰
        config = {
            "critical_ratio_threshold": self._policy.antipattern.critical_ratio_threshold,
            "rigid_budget_threshold": self._policy.antipattern.rigid_budget_threshold,
            "compression_ratio_threshold": self._policy.antipattern.compression_ratio_threshold,
            "ttl_days_threshold": self._policy.antipattern.ttl_days_threshold,
            "routing_effectiveness_threshold": self._policy.antipattern.routing_effectiveness_threshold,
        }

        context = DetectionContext(
            segments=package.segments,
            budget_policy=self._budget_policy,
            budget_allocation=package.budget_allocation,
            audit_log=package.audit_log,
            model=package.model,
            policy_version=package.policy_version,
            config=config,
        )

        # æ‰§è¡Œæ£€æµ‹
        results = detector.detect(context)

        # æ ¹æ®æ ¼å¼è¿”å›ž
        if format == "raw":
            return results
        else:
            return detector.format_report(results, format=format)

    # å¯è§‚æµ‹æ€§ä¾¿æ·æ–¹æ³• diff() / snapshot() / golden_record()
    # é€šè¿‡ ObservabilityMixin æ³¨å…¥ï¼Œå‚è§ facade_observability.py

    def __repr__(self) -> str:
        return (
            f"ContextForge(model='{self._model}', "
            f"max_tokens={self._budget_policy.max_context_tokens:,}, "
            f"policy='{self._policy.name}')"
        )
